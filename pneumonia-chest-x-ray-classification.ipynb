{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810}],"dockerImageVersionId":30043,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Task Description\n\"Pneumonia is an infection that inflames the air sacs (alveoli) in one or both lungs. The air sacs may fill with fluid or pus (purulent material), causing cough with phlegm or pus, fever, chills, and difficulty breathing. A variety of organisms, including bacteria, viruses and fungi, can cause pneumonia. Pneumonia can range in seriousness from mild to life-threatening. It is most serious for infants and young children, people older than age 65, and people with health problems or weakened immune systems.\" ~ [MayoClinic](https://www.mayoclinic.org/diseases-conditions/pneumonia/symptoms-causes/syc-20354204#:~:text=Pneumonia%20is%20an%20infection%20that,and%20fungi%2C%20can%20cause%20pneumonia)\n\n![https://www.nhlbi.nih.gov/sites/default/files/inline-images/pneumonia.png](https://www.nhlbi.nih.gov/sites/default/files/inline-images/pneumonia.png)\n\nChest X-Rays are an invaluable tool used in diagnosing pneumonia. This task requires us to build a model that can detect whether or not an inputted chest x-ray contains signs of pneumonia. The dataset that is part of this task contains 5,863 X-Ray images divided into 2 categories (Pneumonia/Normal).","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import sys\n!conda install --yes --prefix {sys.prefix} timm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nimport os\nimport cv2\nfrom pathlib import Path\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nfrom torchvision import transforms as trf\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom PIL import Image, ImageFile\nfrom torch.optim import lr_scheduler\nimport tqdm\nimport time\nimport timm as timm\nimport math\nfrom sklearn.metrics import precision_recall_fscore_support\nimport joblib\nimport gc\n\n\nimport numpy as np\nimport pandas as pd\nimport random\nimport matplotlib.pyplot as plt\n\n\nimport torch.backends.cudnn as cudnn\n\n\nseed = 100\nos.environ['PYTHONHASHSEED'] = str(seed)\nrandom.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\nnp.random.seed(seed)\ncudnn.deterministic = True\ncudnn.benchmark = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploration: X-Ray Visualisation\nExploring a dataset is an important first step in any machine learning project. This allows researchers and engineers to better understand not only the data they are working with, but also the overall task. \n\nWe will first start by visualising a small subset of the chest x-ray images in the dataset. This should help us create a model tailored for our specific data.","metadata":{}},{"cell_type":"code","source":"drct_path = Path('../input/chest-xray-pneumonia/chest_xray/')\n\nfig, ax = plt.subplots(2, 3, figsize = (15, 9))\nax = ax.ravel()\nplt.tight_layout()\n\nfor i, _set in enumerate(['train', 'test', 'val']):\n    set_path = drct_path.joinpath(_set)\n    \n    normal_img_path = set_path.joinpath('NORMAL')\n    normal_img = plt.imread(normal_img_path.joinpath(os.listdir(normal_img_path)[1]))\n    \n    pneumonia_img_path = set_path.joinpath('PNEUMONIA')\n    pneumonia_img = plt.imread(pneumonia_img_path.joinpath(os.listdir(pneumonia_img_path)[3]))\n    \n    ax[i].imshow(normal_img, cmap = 'gray')\n    ax[i].set_title('Data: {} \\n Class: Normal'.format(_set), fontsize = 13)\n    ax[i+3].imshow(pneumonia_img, cmap = 'gray')\n    ax[i+3].set_title('Data: {} \\n Class: Pneumonia'.format(_set), fontsize = 13)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looking at the above images, we can already make some interesting observations:\n1. All images are greyscale, instead of RGB.\n2. The brightness and contrast can vary significantly across the dataset.\n3. The rotation of examined bodies can also vary.\n\nTherefore, by visualising the dataset we discovered that we need to design a model that works with greyscale images, and is invariant to brightness, contrast, and rotation.","metadata":{}},{"cell_type":"markdown","source":"# Exploration: Class Balance\nUnderstanding the class balance of a dataset is another crucial part of machine learning. A model that has been unknowingly trained on imbalanced data could result in unintended behaviour. For instance, it is common for models trained on heavily imbalanced data to only predict the class with highest representation, irrispective of what class should have been predicted. If we know there is a class balance issue early on, we can take measures to mitigate most issues.","metadata":{}},{"cell_type":"code","source":"train_normal_cnt = len(os.listdir(drct_path.joinpath('train', 'NORMAL')))\ntrain_pneumonia_cnt = len(os.listdir(drct_path.joinpath('train', 'PNEUMONIA')))\n\nval_normal_cnt = len(os.listdir(drct_path.joinpath('val', 'NORMAL')))\nval_pneumonia_cnt = len(os.listdir(drct_path.joinpath('val', 'PNEUMONIA')))\n\ntest_normal_cnt = len(os.listdir(drct_path.joinpath('test', 'NORMAL')))\ntest_pneumonia_cnt = len(os.listdir(drct_path.joinpath('test', 'PNEUMONIA')))\n\ntotal_normal_cnt = train_normal_cnt + val_normal_cnt + test_normal_cnt\ntotal_pneumonia_cnt = train_pneumonia_cnt + val_pneumonia_cnt + test_pneumonia_cnt\n\nprint('Train counts')\nprint('Normal {} - {} Pneumonia'.format(train_normal_cnt, train_pneumonia_cnt))\nprint('\\nVal counts')\nprint('Normal {} - {} Pneumonia'.format(val_normal_cnt, val_pneumonia_cnt))\nprint('\\nTest counts')\nprint('Normal {} - {} Pneumonia'.format(test_normal_cnt, test_pneumonia_cnt))\nprint('\\nTotal counts')\nprint('Normal {} - {} Pneumonia'.format(total_normal_cnt, total_pneumonia_cnt))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is clear that this dataset is heavily biased towards cases of pneumonia. This will affect the way we process our dataset and evaluate our model.","metadata":{}},{"cell_type":"markdown","source":"# Configuration File","metadata":{}},{"cell_type":"code","source":"CONFIG = {\n    'MEAN': [122.79749774, 122.79749774, 122.79749774],\n    'STD': [61.01180544, 61.01180544, 61.01180544],\n    'PNEUMONIA_ID': 1,\n    'NORMAL_ID': 0,\n    'image_dims': (224,224),\n    'recalculate_dataset_stats': False,\n    'max_pixel_val': 255.0,\n    'batch_size': 16,\n    'loader_workers': 4,\n    'smoothing' : 0.00,\n    't1' : 0.8,\n    't2' : 1.2,\n    'train_pkl_loc': 'train_data.pkl',\n    'val_pkl_loc': 'val_data.pkl',\n    'test_pkl_loc': 'test_data.pkl',\n    'train_df_loc': 'train_df.pkl',\n    'val_df_loc': 'val_df.pkl',\n    'test_df_loc': 'test_df.pkl',\n    \n         }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PreProcess Dataset\nIn this section we first index the dataset into train, validation, and test dataframes. During this process we also make sure that the dataset is balanced by replicating the under represented class. \n\nIn most computer vision projects, the datasets are too large to be stored in memory. As such, it is common to load images individually per batch. The downside, however, is that this has noticable overhead, resulting in inefficient use of GPU time. In the following section, we preprocess the images into a dictionary that we later fully load into memory, speeding up the training process significantly. ","metadata":{}},{"cell_type":"code","source":"def index_dataset():\n    # Index the train, validation, and test subsets into their relevant pandas dataframes. \n    # For each image we store the image class, file name, and file location.\n    PNEUMONIA_ID = CONFIG['PNEUMONIA_ID']\n    NORMAL_ID = CONFIG['NORMAL_ID']\n    def build_df(subset, balance_dataset=False):\n        cols = ['Class', 'Name', 'Location']\n        rows = [[],[]]\n        for cls, cls_id in [('NORMAL', NORMAL_ID), ('PNEUMONIA', PNEUMONIA_ID)]:\n            path = drct_path.joinpath(subset, cls)\n            locs = os.listdir(path)\n            for name in locs:\n                rows[cls_id].append([cls_id, name, path.joinpath(name)])\n        if balance_dataset:\n            # If we need to balance the dataset:\n            # Replicate the class with lowest representation using the relevant ratio\n            ratio = len(rows[PNEUMONIA_ID])/len(rows[NORMAL_ID])\n            for i in range(int(ratio)-1):\n                rows[NORMAL_ID].extend(rows[NORMAL_ID])\n            remaining_diff = len(rows[PNEUMONIA_ID]) - len(rows[NORMAL_ID])\n            rows[NORMAL_ID].extend(rows[NORMAL_ID][:remaining_diff])\n            print('NORMAL: {}   -  PNEUMONIA: {}'.format(len(rows[NORMAL_ID]), len(rows[PNEUMONIA_ID])))\n        rows[NORMAL_ID].extend(rows[PNEUMONIA_ID])\n        rows = rows[NORMAL_ID]\n        random.shuffle(rows)\n        return pd.DataFrame(rows, columns=cols)\n    \n    train_df = build_df('train', balance_dataset=True)\n    val_df = build_df('val')\n    test_df = build_df('test')\n    return train_df, val_df, test_df\n\ndef convert_dataset_to_list(df, save_loc, save_df_loc):\n    # During development we noticed that the whole dataset can fit into RAM. \n    # Therefore, we load all the images into a dictionary using the same indexing as the dataframe.\n    # To reduce memory usage, we resize the images beforehand, instead of performing that as part of the augmentation pipeline.\n    path = Path(save_loc)\n    path_df = Path(save_df_loc)\n    if not path.exists():\n        rsz = trf.Resize(CONFIG['image_dims'])\n        new_dataset = {}\n        with tqdm.tqdm(total=len(df)) as pbar:\n            for index, row in df.iterrows():\n                image_location = row['Location']\n                image = Image.open(image_location).convert('RGB')\n                image = rsz(image)\n                new_dataset[index] = image\n                pbar.update(1)\n        joblib.dump(new_dataset, path)\n        joblib.dump(df, path_df)\n    new_dataset = None\n    gc.collect()\n    new_dataset = joblib.load(path)\n    new_df = joblib.load(path_df)\n    return new_dataset, new_df\n    \n        \n\ndef calculate_dataset_stats(locations_df):\n    # Calculate mean and std of input dataframe images\n    length = len(train_df)\n    print(length)\n    img_stack = []\n    for idx in range(length):\n        img = Image.open(locations_df.iloc[idx]['Location']).convert('RGB')\n        rsz = trf.Resize(CONFIG['image_dims'])\n        img2 = rsz.forward(img)\n        img_stack.append(np.array(img2))\n\n    img_stack = np.stack(img_stack)\n    img_stack = np.einsum('ijkl->lijk', img_stack).reshape((3,-1))\n    mean = np.mean(img_stack, -1)\n    std = np.std(img_stack, -1)\n    \n    CONFIG['MEAN'] = mean\n    CONFIG['STD'] = std\n    print(mean, std)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, val_df, test_df = index_dataset()\nif CONFIG['recalculate_dataset_stats']:\n    calculate_dataset_stats(train_df)\ntrain_data, train_df = convert_dataset_to_list(train_df, CONFIG['train_pkl_loc'], CONFIG['train_df_loc'])\nval_data, val_df = convert_dataset_to_list(val_df, CONFIG['val_pkl_loc'], CONFIG['val_df_loc'])\ntest_data, test_df = convert_dataset_to_list(test_df, CONFIG['test_pkl_loc'], CONFIG['test_df_loc'])\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Class","metadata":{}},{"cell_type":"code","source":"class XRayDataset(Dataset):\n    \"\"\"\n    Class to read and load the XRay dataset from disk\n    \"\"\"\n    def __init__(self, df, transform=None, fmix=False, data=None):\n        self.transform = transform\n        self.df = df\n        self.fmix = fmix\n        self.fmix_params={\n                     'alpha': 1.0, \n                     'decay_power': 3.0, \n                     'shape': CONFIG['image_dims'],\n                     'max_soft': True, \n                     'reformulate': False\n                 }\n        self.data = data\n\n    def __len__(self):\n        return len(self.df)\n    \n    def transform_image(self, img):\n        if self.transform is not None:\n            return self.transform(img)\n    \n    def __getitem__(self, idx):\n        if self.data is None:\n            image_location = self.df.iloc[idx]['Location']\n            image = Image.open(image_location).convert('RGB')\n        else:\n            image = self.data[idx]\n        image = self.transform_image(image)\n        label = self.df.iloc[idx]['Class']              \n        return image, label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"markdown","source":"Data augmentation is crucial in preventing the model from overfitting during training. In short, this is the process of transforming the training data without, for the most part, altering the target classification. In general, data augmentation helps by training the model to be robust to the different kinds of noise that is present in real world data. For example, if we have an image of a dog, the position, size, and orientation of the dog does not change the fact that there is a dog in the image. Therefore, the model should still output the same target classification for all those variations. By augmenting the data, we are also training on an expanded the dataset. This allows the model to explore a wider range of the input space, resulting in a more informed decision boundary.\n\n![https://miro.medium.com/max/640/0*Ci5g5EE4pfSCzV3o.jpg](https://miro.medium.com/max/640/0*Ci5g5EE4pfSCzV3o.jpg)\n\nFor this project in particular, data augmentation is also useful in indirectly helping to balance the dataset. As we discussed earlier, the least represented class had its images replicated by a particular ratio. In other words, the model will be training on the same image multiple times in the same epoch, possibly resulting in a heavily biased model. However, since we will be randomly augmenting the training data, every duplicated image is likely to be augmented differently. Thus, effectively, the model will be trained on unique images, even if the original batch had repeated data. \n","metadata":{}},{"cell_type":"code","source":"def get_train_transforms():\n    mean = np.array(CONFIG['MEAN']) / CONFIG['max_pixel_val']\n    std = np.array(CONFIG['STD']) / CONFIG['max_pixel_val']\n    return trf.Compose([\n#             trf.Resize(CONFIG['image_dims']),\n            trf.ColorJitter(brightness=0.2, contrast=0.1),\n            trf.RandomAffine(degrees=20.0, translate=None, scale=None),\n            trf.ToTensor(),\n            trf.Normalize(mean, std)\n        ])\n\ndef get_eval_transforms():\n    mean = np.array(CONFIG['MEAN']) / CONFIG['max_pixel_val']\n    std = np.array(CONFIG['STD']) / CONFIG['max_pixel_val']\n    return trf.Compose([\n            trf.Resize(CONFIG['image_dims']),\n            trf.ToTensor(),\n            trf.Normalize(mean, std)\n        ])\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we pointed out in the Dataset Visualisation section, the dataset has different kinds of noise that need to be accounted for. These are mainly: x-ray brightness, contrast, and body rotation. Therefore, we designed the following augmentation pipeline:\n1. Randomly alter the brightness of the x-ray by up to 20%\n2. Randomly alter the contrast by up to 10%\n3. Randomly rotate the x-ray by up to 20 degrees","metadata":{}},{"cell_type":"markdown","source":"# Data Loaders","metadata":{}},{"cell_type":"code","source":"def get_data_loaders(train_df, val_df, test_df, train_data, val_data, test_data):\n    eval_transforms = get_eval_transforms()\n    \n    train = XRayDataset(train_df, transform=get_train_transforms(), fmix=False, data=train_data)\n    val = XRayDataset(val_df, transform=get_eval_transforms(), data=val_data)\n    test = XRayDataset(test_df, transform=get_eval_transforms(), data=test_data)\n    \n    train_loader = DataLoader(train, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=CONFIG['loader_workers'], drop_last=False)\n    val_loader = DataLoader(val, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=CONFIG['loader_workers'], drop_last=False)\n    test_loader = DataLoader(test, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=CONFIG['loader_workers'], drop_last=False)\n    \n    return train_loader, val_loader, test_loader","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader, val_loader, test_loader = get_data_loaders(train_df, val_df, test_df, train_data, val_data, test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model: Pre-Trained Vision Transformer\nUntil recently, most computer vision tasks have relied solely on convolutional architectures. With the [Vision Transformer (ViT)](https://arxiv.org/abs/2010.11929), researchers have now found a way of applying transformers directly to images, without any major architectural modifications. To do so, ViT first splits an image into a sequence of patches, projecting them into a sequence of embeddings. Subsequently, ViT propagates these dynamic patch embeddings through a standard transformer encoder to generate a task-specific output. The model architecture is shown in the image below.\n\n![https://i.imgur.com/DXnJVqS.png](https://i.imgur.com/DXnJVqS.png)\n\nThe original paper explores multiple ways of projecting the inputted image into embeddings. The simplest option is to divide the image into flattened patches and transforming them using a learned linear projection. The other is to have a more hybrid approach using Convolutional Neural Networks (CNNs). The input embeddings could instead be generated by segmenting the feature maps of any CNN into patches, and projecting them into dynamic embeddings that can be propagated through a transformer.","metadata":{}},{"cell_type":"code","source":"class ViTModel(nn.Module):\n    def __init__(self):\n        super(ViTModel, self).__init__()\n        self.feature_extractor = timm.create_model('vit_small_resnet50d_s3_224', num_classes=2, attn_drop_rate=0.0, drop_path_rate=0.0,pretrained=True)\n\n    def forward(self, x):\n        out = x\n        out = self.feature_extractor(out)  \n        return out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this project we use a pre-trained, hybrid ViT that uses a ResNet to extract feature maps from the inputted image. This allows the transformer to receive more informative features as input.","metadata":{}},{"cell_type":"markdown","source":"# Bi-Tempered Logistic Loss","metadata":{}},{"cell_type":"markdown","source":"Research shows that convex losses commonly used for classification tasks, like the softmax loss, are not robust against outliers. This is partly due to their unbounded nature. An unbound function will return high loss values, resulting in large gradient updates for misclassified outliers. Consequently, this lack of robustness results in a decision boundary that is heavily influenced by singular outlying data points.\n\n![https://i.imgur.com/WwdKojh.png](https://i.imgur.com/WwdKojh.png)\n\nAnother issue, particularly with the softmax loss, is the exponentially decaying tail of the softmax function itself. Whenever there are outliers close to the decision boundary, the short tail of the softmax forces the model to give them higher importance. In contrast, heavy-tailed alternatives significantly improve the robustness of the loss towards such outliers.\n\nThe [Robust Bi-Tempered Logistic Loss](https://papers.nips.cc/paper/2019/hash/8cd7775f9129da8b5bf787a063d8426e-Abstract.html) addresses these issues through a bounded loss with tail-heaviness. The researchers did this by replacing the log and softmax in the softmax loss, with their respective tempered versions. The boundedness and tail-heaviness can be controlled through two hyperparameters: t1 and t2. When 0 <= t1 < 1, the loss is bounded, while when t2 > 1, the loss has a heavy tail.\n\n![https://i.imgur.com/pWLU7hT.png](https://i.imgur.com/pWLU7hT.png)\n\nThe difference between softmax (logistic) loss and the Bi-Tempered Logistic Loss is shown in the image below.\n\n![https://i.imgur.com/ppp02AJ.png](https://i.imgur.com/ppp02AJ.png)\n\n","metadata":{}},{"cell_type":"code","source":"# Code taken from https://github.com/fhopfmueller/bi-tempered-loss-pytorch/blob/master/bi_tempered_loss_pytorch.py\n\ndef log_t(u, t):\n    \"\"\"Compute log_t for `u'.\"\"\"\n    if t==1.0:\n        return u.log()\n    else:\n        return (u.pow(1.0 - t) - 1.0) / (1.0 - t)\n\ndef exp_t(u, t):\n    \"\"\"Compute exp_t for `u'.\"\"\"\n    if t==1:\n        return u.exp()\n    else:\n        return (1.0 + (1.0-t)*u).relu().pow(1.0 / (1.0 - t))\n\ndef compute_normalization_fixed_point(activations, t, num_iters):\n\n    \"\"\"Returns the normalization value for each example (t > 1.0).\n    Args:\n      activations: A multi-dimensional tensor with last dimension `num_classes`.\n      t: Temperature 2 (> 1.0 for tail heaviness).\n      num_iters: Number of iterations to run the method.\n    Return: A tensor of same shape as activation with the last dimension being 1.\n    \"\"\"\n    mu, _ = torch.max(activations, -1, keepdim=True)\n    normalized_activations_step_0 = activations - mu\n\n    normalized_activations = normalized_activations_step_0\n\n    for _ in range(num_iters):\n        logt_partition = torch.sum(\n                exp_t(normalized_activations, t), -1, keepdim=True)\n        normalized_activations = normalized_activations_step_0 * \\\n                logt_partition.pow(1.0-t)\n\n    logt_partition = torch.sum(\n            exp_t(normalized_activations, t), -1, keepdim=True)\n    normalization_constants = - log_t(1.0 / logt_partition, t) + mu\n\n    return normalization_constants\n\ndef compute_normalization_binary_search(activations, t, num_iters):\n\n    \"\"\"Returns the normalization value for each example (t < 1.0).\n    Args:\n      activations: A multi-dimensional tensor with last dimension `num_classes`.\n      t: Temperature 2 (< 1.0 for finite support).\n      num_iters: Number of iterations to run the method.\n    Return: A tensor of same rank as activation with the last dimension being 1.\n    \"\"\"\n\n    mu, _ = torch.max(activations, -1, keepdim=True)\n    normalized_activations = activations - mu\n\n    effective_dim = \\\n        torch.sum(\n                (normalized_activations > -1.0 / (1.0-t)).to(torch.int32),\n            dim=-1, keepdim=True).to(activations.dtype)\n\n    shape_partition = activations.shape[:-1] + (1,)\n    lower = torch.zeros(shape_partition, dtype=activations.dtype, device=activations.device)\n    upper = -log_t(1.0/effective_dim, t) * torch.ones_like(lower)\n\n    for _ in range(num_iters):\n        logt_partition = (upper + lower)/2.0\n        sum_probs = torch.sum(\n                exp_t(normalized_activations - logt_partition, t),\n                dim=-1, keepdim=True)\n        update = (sum_probs < 1.0).to(activations.dtype)\n        lower = torch.reshape(\n                lower * update + (1.0-update) * logt_partition,\n                shape_partition)\n        upper = torch.reshape(\n                upper * (1.0 - update) + update * logt_partition,\n                shape_partition)\n\n    logt_partition = (upper + lower)/2.0\n    return logt_partition + mu\n\nclass ComputeNormalization(torch.autograd.Function):\n    \"\"\"\n    Class implementing custom backward pass for compute_normalization. See compute_normalization.\n    \"\"\"\n    @staticmethod\n    def forward(ctx, activations, t, num_iters):\n        if t < 1.0:\n            normalization_constants = compute_normalization_binary_search(activations, t, num_iters)\n        else:\n            normalization_constants = compute_normalization_fixed_point(activations, t, num_iters)\n\n        ctx.save_for_backward(activations, normalization_constants)\n        ctx.t=t\n        return normalization_constants\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        activations, normalization_constants = ctx.saved_tensors\n        t = ctx.t\n        normalized_activations = activations - normalization_constants \n        probabilities = exp_t(normalized_activations, t)\n        escorts = probabilities.pow(t)\n        escorts = escorts / escorts.sum(dim=-1, keepdim=True)\n        grad_input = escorts * grad_output\n        \n        return grad_input, None, None\n\ndef compute_normalization(activations, t, num_iters=5):\n    \"\"\"Returns the normalization value for each example. \n    Backward pass is implemented.\n    Args:\n      activations: A multi-dimensional tensor with last dimension `num_classes`.\n      t: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n      num_iters: Number of iterations to run the method.\n    Return: A tensor of same rank as activation with the last dimension being 1.\n    \"\"\"\n    return ComputeNormalization.apply(activations, t, num_iters)\n\ndef tempered_sigmoid(activations, t, num_iters = 5):\n    \"\"\"Tempered sigmoid function.\n    Args:\n      activations: Activations for the positive class for binary classification.\n      t: Temperature tensor > 0.0.\n      num_iters: Number of iterations to run the method.\n    Returns:\n      A probabilities tensor.\n    \"\"\"\n    internal_activations = torch.stack([activations,\n        torch.zeros_like(activations)],\n        dim=-1)\n    internal_probabilities = tempered_softmax(internal_activations, t, num_iters)\n    return internal_probabilities[..., 0]\n\n\ndef tempered_softmax(activations, t, num_iters=5):\n    \"\"\"Tempered softmax function.\n    Args:\n      activations: A multi-dimensional tensor with last dimension `num_classes`.\n      t: Temperature > 1.0.\n      num_iters: Number of iterations to run the method.\n    Returns:\n      A probabilities tensor.\n    \"\"\"\n    if t == 1.0:\n        return activations.softmax(dim=-1)\n\n    normalization_constants = compute_normalization(activations, t, num_iters)\n    return exp_t(activations - normalization_constants, t)\n\ndef bi_tempered_binary_logistic_loss(activations,\n        labels,\n        t1,\n        t2,\n        label_smoothing = 0.0,\n        num_iters=5,\n        reduction='mean'):\n\n    \"\"\"Bi-Tempered binary logistic loss.\n    Args:\n      activations: A tensor containing activations for class 1.\n      labels: A tensor with shape as activations, containing probabilities for class 1\n      t1: Temperature 1 (< 1.0 for boundedness).\n      t2: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n      label_smoothing: Label smoothing\n      num_iters: Number of iterations to run the method.\n    Returns:\n      A loss tensor.\n    \"\"\"\n    internal_activations = torch.stack([activations,\n        torch.zeros_like(activations)],\n        dim=-1)\n    internal_labels = torch.stack([labels.to(activations.dtype),\n        1.0 - labels.to(activations.dtype)],\n        dim=-1)\n    return bi_tempered_logistic_loss(internal_activations, \n            internal_labels,\n            t1,\n            t2,\n            label_smoothing = label_smoothing,\n            num_iters = num_iters,\n            reduction = reduction)\n\ndef bi_tempered_logistic_loss(activations,\n        labels,\n        t1,\n        t2,\n        label_smoothing=0.0,\n        num_iters=5,\n        reduction = 'mean'):\n\n    \"\"\"Bi-Tempered Logistic Loss.\n    Args:\n      activations: A multi-dimensional tensor with last dimension `num_classes`.\n      labels: A tensor with shape and dtype as activations (onehot), \n        or a long tensor of one dimension less than activations (pytorch standard)\n      t1: Temperature 1 (< 1.0 for boundedness).\n      t2: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n      label_smoothing: Label smoothing parameter between [0, 1). Default 0.0.\n      num_iters: Number of iterations to run the method. Default 5.\n      reduction: ``'none'`` | ``'mean'`` | ``'sum'``. Default ``'mean'``.\n        ``'none'``: No reduction is applied, return shape is shape of\n        activations without the last dimension.\n        ``'mean'``: Loss is averaged over minibatch. Return shape (1,)\n        ``'sum'``: Loss is summed over minibatch. Return shape (1,)\n    Returns:\n      A loss tensor.\n    \"\"\"\n\n    if len(labels.shape)<len(activations.shape): #not one-hot\n        labels_onehot = torch.zeros_like(activations)\n        labels_onehot.scatter_(1, labels[..., None], 1)\n    else:\n        labels_onehot = labels\n\n    if label_smoothing > 0:\n        num_classes = labels_onehot.shape[-1]\n        labels_onehot = ( 1 - label_smoothing * num_classes / (num_classes - 1) ) \\\n                * labels_onehot + \\\n                label_smoothing / (num_classes - 1)\n\n    probabilities = tempered_softmax(activations, t2, num_iters)\n\n    loss_values = labels_onehot * log_t(labels_onehot + 1e-10, t1) \\\n            - labels_onehot * log_t(probabilities, t1) \\\n            - labels_onehot.pow(2.0 - t1) / (2.0 - t1) \\\n            + probabilities.pow(2.0 - t1) / (2.0 - t1)\n    loss_values = loss_values.sum(dim = -1) #sum over classes\n\n    if reduction == 'none':\n        return loss_values\n    if reduction == 'sum':\n        return loss_values.sum()\n    if reduction == 'mean':\n        return loss_values.mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Instead of the traditional Binary Cross-Entropy Loss function, we opted for the [Robust Bi-Tempered Logistic Loss](https://papers.nips.cc/paper/2019/hash/8cd7775f9129da8b5bf787a063d8426e-Abstract.html) published in NeurIPS 2019. This should help the model's generalisation by learning a more robust decision boundary, despite the small amount of training data.","metadata":{}},{"cell_type":"markdown","source":"# Experiment Builder","metadata":{}},{"cell_type":"code","source":"class ExperimentBuilder(nn.Module):\n    def __init__(self, network_model, num_epochs, train_data, val_data,\n                 test_data, weight_decay_coefficient, lr, use_gpu):\n        \"\"\"\n        Initializes an ExperimentBuilder object. Such an object takes care of running training and evaluation of a deep net\n        on a given dataset. It also takes care of saving per epoch models and automatically inferring the best val model\n        to be used for evaluating the test set metrics.\n        :param network_model: A pytorch nn.Module which implements a network architecture.\n        :param experiment_name: The name of the experiment. This is used mainly for keeping track of the experiment and creating and directory structure that will be used to save logs, model parameters and other.\n        :param num_epochs: Total number of epochs to run the experiment\n        :param train_data: An object of the DataProvider type. Contains the training set.\n        :param val_data: An object of the DataProvider type. Contains the val set.\n        :param test_data: An object of the DataProvider type. Contains the test set.\n        :param weight_decay_coefficient: A float indicating the weight decay to use with the adam optimizer.\n        :param use_gpu: A boolean indicating whether to use a GPU or not.\n        :param continue_from_epoch: An int indicating whether we'll start from scrach (-1) or whether we'll reload a previously saved model of epoch 'continue_from_epoch' and continue training from there.\n        \"\"\"\n        super(ExperimentBuilder, self).__init__()\n    \n        self.model = network_model\n        \n        if torch.cuda.device_count() > 1 and use_gpu:\n            self.device = torch.cuda.current_device()\n            self.model.to(self.device)\n            self.model = nn.DataParallel(module=self.model)\n            print('Use Multi GPU', self.device)\n        elif torch.cuda.device_count() == 1 and use_gpu:\n            self.device =  torch.cuda.current_device()\n            self.model.to(self.device)  # sends the model from the cpu to the gpu\n            print('Use GPU', self.device)\n        else:\n            print(\"use CPU\")\n            self.device = torch.device('cpu')  # sets the device to be CPU\n            print(self.device)\n        \n            \n#         self.model.reset_parameters()  # re-initialize network parameters\n        self.train_data = train_data\n        self.val_data = val_data\n        self.test_data = test_data\n\n        self.num_epochs = num_epochs\n        \n        self.optimizer = optim.Adam(self.parameters(), amsgrad=False, lr=lr,\n                                    weight_decay=weight_decay_coefficient)\n#         self.learning_rate_scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, num_epochs)\n        self.learning_rate_scheduler = self._create_lr_scheduler()\n\n\n        self.state = dict()\n        self.starting_epoch = 0\n\n    def get_num_parameters(self):\n        total_num_params = 0\n        for param in self.parameters():\n            total_num_params += np.prod(param.shape)\n\n        return total_num_params\n\n    def get_optimiser(self):\n        return self.optimizer  \n    \n    def _create_lr_scheduler(self):\n        num_epochs = self.num_epochs\n        num_warmup_steps = 3\n        num_cycles = 0.5\n\n        # Code from huggingface optimisers\n        def lr_lambda(current_step):\n            if current_step < num_warmup_steps:\n                return float(current_step) / float(max(1, num_warmup_steps))\n            progress = float(current_step - num_warmup_steps) / float(max(1, num_epochs - num_warmup_steps))\n            return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress)))\n        \n        \n        return optim.lr_scheduler.LambdaLR(self.optimizer, lr_lambda, -1)\n    \n    def run_train_iter(self, x, y):\n            \"\"\"\n            Receives the inputs and targets for the model and runs a training iteration. Returns loss and accuracy metrics.\n            :param x: The inputs to the model. A numpy array of shape batch_size, channels, height, width\n            :param y: The targets for the model. A numpy array of shape batch_size, num_classes\n            :return: the loss and accuracy for this batch\n            \"\"\"\n            self.train()\n            x, y = x.float().to(device=self.device), y.long().to(\n            device=self.device)  # send data to device as torch tensors\n            out = self.model.forward(x)  # forward the data in the model\n\n            loss = bi_tempered_logistic_loss(out, y, t1=CONFIG['t1'], t2=CONFIG['t2'], label_smoothing=CONFIG['smoothing'])\n            \n            self.optimizer.zero_grad()  # set all weight grads from previous training iters to 0\n            loss.backward()  # backpropagate to compute gradients for current iter loss\n            self.optimizer.step()  # update network parameters\n            # self.learning_rate_scheduler.step(epoch=self.current_epoch)\n\n            _, predicted = torch.max(out.data, 1)  # get argmax of predictions\n            accuracy = np.mean(list(predicted.eq(y.data).cpu()))  # compute accuracy\n            prec, rec, f1, _ = precision_recall_fscore_support(y.cpu().data.numpy(), predicted.cpu().data.numpy(), average='macro')\n            return loss.cpu().data.numpy(), accuracy, prec, rec, f1\n        \n    def run_evaluation_iter(self, x, y):\n        \"\"\"\n        Receives the inputs and targets for the model and runs an evaluation iterations. Returns loss and accuracy metrics.\n        :param x: The inputs to the model. A numpy array of shape batch_size, channels, height, width\n        :param y: The targets for the model. A numpy array of shape batch_size, num_classes\n        :return: the loss and accuracy for this batch\n        \"\"\"\n        self.eval()  # sets the system to validation mode\n        x, y = x.float().to(device=self.device), y.long().to(\n            device=self.device)  # convert data to pytorch tensors and send to the computation device\n        out = self.model.forward(x)  # forward the data in the model\n        \n        loss = bi_tempered_logistic_loss(out, y, t1=CONFIG['t1'], t2=CONFIG['t2'], label_smoothing=CONFIG['smoothing'])\n\n        _, predicted = torch.max(out.data, 1)  # get argmax of predictions\n        accuracy = np.mean(list(predicted.eq(y.data).cpu()))  # compute accuracy\n        prec, rec, f1, _ = precision_recall_fscore_support(y.cpu().data.numpy(), predicted.cpu().data.numpy(), average='macro')\n        return loss.cpu().data.numpy(), accuracy, prec, rec, f1\n                                                                            \n    def run_experiment(self):\n        \"\"\"\n        Runs experiment train and evaluation iterations, saving the model and best val model and val model accuracy after each epoch\n        :return: The summary current_epoch_losses from starting epoch to total_epochs.\n        \"\"\"\n        print('Starting Training')\n        print('Model Parameters: {}'.format(self.get_num_parameters()))\n        total_losses = {\"train_acc\": [], \"train_loss\": [], \"val_acc\": [],\n                        \"val_loss\": []}  # initialize a dict to keep the per-epoch metrics\n        best_test_metrics = {'f1':0, 'acc':0, 'loss':0}\n        best_val_loss = math.inf\n        epochs_since_improv = 0\n        for i, epoch_idx in enumerate(range(self.starting_epoch, self.num_epochs)):\n            epoch_start_time = time.time()\n            current_epoch_losses = {\"train_acc\": [], \"train_loss\": [], \"train_f1\": [], \n                                    \"val_acc\": [], \"val_loss\": [], \"val_f1\": [],\n                                    \"test_acc\": [], \"test_loss\": [], \"test_f1\": []}\n            self.current_epoch = epoch_idx\n            with tqdm.tqdm(total=len(self.train_data)) as pbar_train:  # create a progress bar for training\n                for idx, (x, y) in enumerate(self.train_data):  # get data batches\n                    loss, accuracy, prec, rec, f1 = self.run_train_iter(x=x, y=y) # take a training iter step\n                    self.learning_rate_scheduler.step()\n                    current_epoch_losses[\"train_loss\"].append(loss)  # add current iter loss to the train loss list\n                    current_epoch_losses[\"train_acc\"].append(accuracy)  # add current iter acc to the train acc list\n                    current_epoch_losses[\"train_f1\"].append(f1)  # add current iter f1 to the train acc list\n                    pbar_train.update(1)\n                    pbar_train.set_description(\"Epoch {} - loss: {:.4f}, acc: {:.4f}, F1: {:.4f}\".format(self.current_epoch, loss, accuracy, f1))\n            avg_train_loss = np.mean(np.array(current_epoch_losses[\"train_loss\"]))\n            avg_train_acc = np.mean(np.array(current_epoch_losses[\"train_acc\"]))\n            avg_train_f1 = np.mean(np.array(current_epoch_losses[\"train_f1\"]))\n            \n            with tqdm.tqdm(total=len(self.val_data)) as pbar_val:  # create a progress bar for validation\n                for x, y in self.val_data:  # get data batches\n                    loss, accuracy, prec, rec, f1  = self.run_evaluation_iter(x=x, y=y)  # run a validation iter\n                    current_epoch_losses[\"val_loss\"].append(loss)  # add current iter loss to val loss list.\n                    current_epoch_losses[\"val_acc\"].append(accuracy)  # add current iter acc to val acc lst.\n                    current_epoch_losses[\"val_f1\"].append(f1)  # add current iter f1 to the train acc list\n                    pbar_val.update(1)  # add 1 step to the progress bar\n                    pbar_val.set_description(\"Epoch {} - loss: {:.4f}, acc: {:.4f}, F1: {:.4f}\".format(self.current_epoch, loss, accuracy, f1))\n            avg_val_loss = np.mean(np.array(current_epoch_losses[\"val_loss\"]))\n            avg_val_acc = np.mean(np.array(current_epoch_losses['val_acc']))\n            avg_val_f1 = np.mean(np.array(current_epoch_losses['val_f1']))  \n        \n            with tqdm.tqdm(total=len(self.test_data)) as pbar_test:  # ini a progress bar\n                for x, y in self.test_data:  # sample batch\n                    loss, accuracy, prec, rec, f1 = self.run_evaluation_iter(x=x, y=y)  # compute loss and accuracy by running an evaluation step\n                    current_epoch_losses[\"test_loss\"].append(loss)  # save test loss\n                    current_epoch_losses[\"test_acc\"].append(accuracy)  # save test accuracy\n                    current_epoch_losses[\"test_f1\"].append(f1)  # save test accuracy\n                    pbar_test.update(1)  # update progress bar status\n                    pbar_test.set_description(\n                        \"loss: {:.4f}, accuracy: {:.4f}\".format(loss, accuracy))  # update progress bar string output\n            \n            test_acc = np.mean(np.array(current_epoch_losses['test_acc']))\n            test_f1 = np.mean(np.array(current_epoch_losses['test_f1']))\n            \n            print(\"Test Acc: {:.4f}  -  Test F1: {:.4f} \\n Val Loss: {:.4f}  -  Val Acc: {:.4f}  -  Val F1: {:.4f} \\n Train Loss: {:.4f}  -  Train Acc: {:.4f} - Train F1: {:.4f}\"\n                  .format(test_acc, test_f1, avg_val_loss, avg_val_acc, avg_val_f1, avg_train_loss, avg_train_acc, avg_train_f1)) \n            \n            if avg_val_loss < best_val_loss:\n                best_val_loss = avg_val_loss\n                epochs_since_improv = 0\n                best_test_metrics['f1'] = current_epoch_losses[\"test_f1\"][-1]\n                best_test_metrics['acc'] = current_epoch_losses[\"test_acc\"][-1]\n                best_test_metrics['loss'] = current_epoch_losses[\"test_loss\"][-1]\n            else:\n                epochs_since_improv += 1\n            \n            if epochs_since_improv == 3:\n                break\n        print('Final Test Results \\n', best_test_metrics)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed = 100\nos.environ['PYTHONHASHSEED'] = str(seed)\nrandom.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\nnp.random.seed(seed)\ncudnn.deterministic = True\ncudnn.benchmark = False\n\nmodel = ViTModel()\nexp = ExperimentBuilder(network_model=model, num_epochs=20, train_data=train_loader, val_data=val_loader,\n                 test_data=test_loader, weight_decay_coefficient=1e-3, lr=1e-4, use_gpu=True)\nexp.run_experiment()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final Test Results\nF1 Score: 92.27%\n\nAccuracy: 93.75%","metadata":{}},{"cell_type":"markdown","source":"# Conclusion\nIn this project, we have shown how to perform pneumonia detection from chest x-ray images using state-of-the-art transformers. During the dataset analysis process, we discovered a large imbalance between the classes. To remedy this, we balanced the data through repetitions and used carefully selected augmentations to mitigate some of the issues with our balancing methodology. Instead of using traditional loss functions, we opted for the Bi-Tempered Robust Logistic Loss for a more robust decision boundary. Finally, we fine-tuned a pre-trained Vision Transformer, achieving an F1 score of 92.27%. ","metadata":{}}]}