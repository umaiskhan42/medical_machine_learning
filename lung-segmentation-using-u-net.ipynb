{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7773,"sourceType":"datasetVersion","datasetId":4667},{"sourceId":258315,"sourceType":"datasetVersion","datasetId":108201},{"sourceId":3324348,"sourceType":"datasetVersion","datasetId":576013}],"dockerImageVersionId":30018,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport PIL\n## checking for xrays and their respective masks\nfrom glob import glob\nimport re\nfrom collections import defaultdict\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom skimage import measure\n\nDIR = \"/kaggle/input/chest-xray-masks-and-labels/data/\"\n\nlung_image_paths = glob(os.path.join(DIR,\"Lung Segmentation/CXR_png/*.png\"))\nmask_image_paths = glob(os.path.join(DIR,\"Lung Segmentation/masks/*.png\"))\n\nrelated_paths = defaultdict(list)\n\nfor img_path in lung_image_paths:\n    img_match = re.search(\"CXR_png/(.*)\\.png$\", img_path)\n    if img_match:\n        img_name = img_match.group(1)\n    for mask_path in mask_image_paths:\n        mask_match = re.search(img_name, mask_path)\n        if mask_match:\n            related_paths[\"image_path\"].append(img_path)\n            related_paths[\"mask_path\"].append(mask_path)\n\npaths_df = pd.DataFrame.from_dict(related_paths)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2023-12-02T09:33:15.908322Z","iopub.execute_input":"2023-12-02T09:33:15.908750Z","iopub.status.idle":"2023-12-02T09:33:16.790960Z","shell.execute_reply.started":"2023-12-02T09:33:15.908718Z","shell.execute_reply":"2023-12-02T09:33:16.789992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\nimport os\nFIND_FOLDER = r'/kaggle/input/chest-xray-masks-and-labels/Lung Segmentation/CXR_png/'\nimages_files = glob.glob(os.path.join(FIND_FOLDER, '*.png'))\nprint(len(images_files), \"Files Found.\")","metadata":{"execution":{"iopub.status.busy":"2023-12-02T09:33:20.929700Z","iopub.execute_input":"2023-12-02T09:33:20.930096Z","iopub.status.idle":"2023-12-02T09:33:20.946582Z","shell.execute_reply.started":"2023-12-02T09:33:20.930061Z","shell.execute_reply":"2023-12-02T09:33:20.945476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xray_num = 5\nimg_path = paths_df[\"image_path\"][xray_num]\nmask_path = paths_df[\"mask_path\"][xray_num]\n\nimg = PIL.Image.open(img_path)\nmask = PIL.Image.open(mask_path)\n\nfig = plt.figure(figsize = (10,10))\n\nax1 = fig.add_subplot(2,2,1)\nax1.imshow(img, cmap = \"gray\")\nax2 = fig.add_subplot(2,2,2)\nax2.imshow(mask, cmap = \"gray\")","metadata":{"execution":{"iopub.status.busy":"2023-12-02T09:33:31.285455Z","iopub.execute_input":"2023-12-02T09:33:31.285855Z","iopub.status.idle":"2023-12-02T09:33:32.797768Z","shell.execute_reply.started":"2023-12-02T09:33:31.285810Z","shell.execute_reply":"2023-12-02T09:33:32.796737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nimport cv2\ndef prepare_train_test(df = pd.DataFrame(), resize_shape = tuple(), color_mode = \"rgb\"):\n    img_array = list()\n    mask_array = list()\n\n    for image_path in tqdm(paths_df.image_path):\n        resized_image = cv2.resize(cv2.imread(image_path),resize_shape)\n        resized_image = resized_image/255.\n        if color_mode == \"gray\":\n            img_array.append(resized_image[:,:,0])\n        elif color_mode == \"rgb\":\n            img_array.append(resized_image[:,:,:])\n      # img_array.append(resized_image)\n  \n    for mask_path in tqdm(paths_df.mask_path):\n        resized_mask = cv2.resize(cv2.imread(mask_path),resize_shape)\n        resized_mask = resized_mask/255.\n        mask_array.append(resized_mask[:,:,0])\n        # mask_array.append(resized_image)\n\n    return img_array, mask_array\n\nimg_array, mask_array = prepare_train_test(df = paths_df, resize_shape = (256,256), color_mode = \"gray\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T09:33:37.276247Z","iopub.execute_input":"2023-12-02T09:33:37.276630Z","iopub.status.idle":"2023-12-02T09:36:52.168334Z","shell.execute_reply.started":"2023-12-02T09:33:37.276596Z","shell.execute_reply":"2023-12-02T09:36:52.167123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nimport cv2\ndef prepare_train_test1(df = pd.DataFrame(), resize_shape = tuple(), color_mode = \"gray\"):\n    covid_array = list()\n   \n\n    for covid_path in tqdm(paths_dfc.covid_path):\n        resized_image = cv2.resize(cv2.imread(covid_path),resize_shape)\n        resized_image = resized_image/255.\n        if color_mode == \"gray\":\n            covid_array.append(resized_image[:,:,0])\n        #elif color_mode == \"rgb\":\n            #covid_array.append(resized_image[:,:,:])\n      # img_array.append(resized_image)\n  \n    return covid_array\n\ncovid_array = prepare_train_test1(df = paths_dfc, resize_shape = (256,256), color_mode = \"gray\")","metadata":{"execution":{"iopub.status.busy":"2023-12-02T09:37:44.609700Z","iopub.execute_input":"2023-12-02T09:37:44.610090Z","iopub.status.idle":"2023-12-02T09:37:44.642423Z","shell.execute_reply.started":"2023-12-02T09:37:44.610053Z","shell.execute_reply":"2023-12-02T09:37:44.640838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimg_train, img_test, mask_train, mask_test = train_test_split(img_array, mask_array, test_size = 0.2, random_state= 42)\n\nimg_side_size = 256\nimg_train = np.array(img_train).reshape(len(img_train), img_side_size, img_side_size)\nimg_test = np.array(img_test).reshape(len(img_test), img_side_size, img_side_size)\nmask_train = np.array(mask_train).reshape(len(mask_train), img_side_size, img_side_size)\nmask_test = np.array(mask_test).reshape(len(mask_test), img_side_size, img_side_size)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T09:38:35.357520Z","iopub.execute_input":"2023-12-02T09:38:35.358021Z","iopub.status.idle":"2023-12-02T09:38:35.890917Z","shell.execute_reply.started":"2023-12-02T09:38:35.357980Z","shell.execute_reply":"2023-12-02T09:38:35.890070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#img_side_size = 256\n#covid_array = np.array(covid_array).reshape(len(covid_array), img_side_size, img_side_size, 1)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### U-net \n\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras import backend as keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom tensorflow.keras.activations import *\n\ndef dice_coef(y_true, y_pred):\n    y_true_f = keras.flatten(y_true)\n    y_pred_f = keras.flatten(y_pred)\n    intersection = keras.sum(y_true_f * y_pred_f)\n    return (2. * intersection + 1) / (keras.sum(y_true_f) + keras.sum(y_pred_f) + 1)\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\ndef unet(input_size=(256,256,1)):\n    inputs = Input(input_size)\n    \n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n    \n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n    \n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n   \n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n    \n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\n    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n\n    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n\n    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n\n    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n\n    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n\n    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n\n    return Model(inputs=[inputs], outputs=[conv10])","metadata":{"execution":{"iopub.status.busy":"2023-12-02T09:38:41.054365Z","iopub.execute_input":"2023-12-02T09:38:41.054757Z","iopub.status.idle":"2023-12-02T09:38:41.130972Z","shell.execute_reply.started":"2023-12-02T09:38:41.054717Z","shell.execute_reply":"2023-12-02T09:38:41.130131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 50\nmodel = unet(input_size=(256,256,1))\nmodel.compile(optimizer=Adam(lr=5*1e-4), loss=\"binary_crossentropy\", \\\n                  metrics=[dice_coef, 'binary_accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-02T09:38:50.004149Z","iopub.execute_input":"2023-12-02T09:38:50.004537Z","iopub.status.idle":"2023-12-02T09:38:52.622055Z","shell.execute_reply.started":"2023-12-02T09:38:50.004504Z","shell.execute_reply":"2023-12-02T09:38:52.621069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, to_file='model.png')","metadata":{"execution":{"iopub.status.busy":"2023-12-02T09:38:59.197355Z","iopub.execute_input":"2023-12-02T09:38:59.197763Z","iopub.status.idle":"2023-12-02T09:38:59.915950Z","shell.execute_reply.started":"2023-12-02T09:38:59.197724Z","shell.execute_reply":"2023-12-02T09:38:59.914798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_weights.best.hdf5\".format('cxr_reg')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='loss', #verbose=1, \n                             save_best_only=True, #mode='min', \n                             save_weights_only = True)\n\n\nearly = EarlyStopping(monitor=\"loss\", \n                      #mode=\"min\", \n                      patience=10) # probably needs to be more patient, but kaggle time is limited\ncallbacks_list = [checkpoint, early]","metadata":{"execution":{"iopub.status.busy":"2023-12-02T09:39:08.634426Z","iopub.execute_input":"2023-12-02T09:39:08.634842Z","iopub.status.idle":"2023-12-02T09:39:08.643134Z","shell.execute_reply.started":"2023-12-02T09:39:08.634804Z","shell.execute_reply":"2023-12-02T09:39:08.641951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#earlystopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n\nhistory = model.fit(x = img_train, \n                    y = mask_train, \n                    validation_data = (img_test, mask_test), \n                    epochs = 30, \n                    batch_size = 8,\n                   callbacks = callbacks_list)\nmodel.save('my_model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-12-02T09:50:01.700876Z","iopub.execute_input":"2023-12-02T09:50:01.701285Z","iopub.status.idle":"2023-12-02T09:53:04.899086Z","shell.execute_reply.started":"2023-12-02T09:50:01.701253Z","shell.execute_reply":"2023-12-02T09:53:04.897946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('my_model.h5') ","metadata":{"execution":{"iopub.status.busy":"2023-12-02T09:53:15.442579Z","iopub.execute_input":"2023-12-02T09:53:15.443002Z","iopub.status.idle":"2023-12-02T09:53:15.769044Z","shell.execute_reply.started":"2023-12-02T09:53:15.442960Z","shell.execute_reply":"2023-12-02T09:53:15.767904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_on_image(model, img_array, img_num, img_side_size = 256):\n    \n    pred = model.predict(img_array[img_num].reshape(1,img_side_size,img_side_size,1))\n    pred[pred>0.5] = 1.0\n    pred[pred<0.5] = 0.0\n    fig = plt.figure(figsize = (15,10))\n    \n    plt.subplot(1,4,1)\n    plt.imshow(pred.reshape(img_side_size, img_side_size), cmap = \"gray\")\n    plt.title(\"Prediction\")\n    plt.axis(\"off\")\n    \n    plt.subplot(1,4,2)\n    plt.imshow(mask_test[img_num].reshape(img_side_size, img_side_size), cmap = \"gray\")\n    plt.title(\"Actual\");\n    plt.axis(\"off\")\n    \n    plt.subplot(1,4,3)\n    plt.imshow(mask_test[img_num].reshape(img_side_size, img_side_size), cmap = \"gray\", alpha = 0.5)\n    plt.imshow(pred.reshape(img_side_size, img_side_size),cmap = \"PuBu\", alpha = 0.3)\n    plt.title(\"Overlap\")\n    plt.axis(\"off\")\n    \n    plt.subplot(1,4,4)\n    plt.imshow(img_array[img_num].reshape(img_side_size, img_side_size), cmap = \"gray\")\n    plt.title(\"Original\")\n    plt.axis(\"off\")\n    \n    return pred\n\ndef dice_coef_test(y_true, y_pred):\n    y_true_f = y_true.flatten()\n    y_pred_f = y_pred.flatten()\n    union = np.sum(y_true_f) + np.sum(y_pred_f)\n    if union==0: return 1\n    intersection = np.sum(y_true_f * y_pred_f)\n    return 2. * intersection / union\n\nIMG_NUM = 3 #Melhor img_num 12 (0.98) Pior img_num 10 (0.9)\nprediction = test_on_image(model, img_array = img_test, img_num = IMG_NUM, img_side_size = 256)\ndice_coef_test(y_true = mask_test[IMG_NUM], y_pred = prediction)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T09:54:38.148814Z","iopub.execute_input":"2023-12-02T09:54:38.149281Z","iopub.status.idle":"2023-12-02T09:54:39.242967Z","shell.execute_reply.started":"2023-12-02T09:54:38.149235Z","shell.execute_reply":"2023-12-02T09:54:39.241834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_metrics(history):\n    fig = plt.figure(figsize = (10,10))\n    plt.subplot(2,2,1)\n    plt.plot(history.history[\"loss\"], label = \"training loss\")\n    plt.plot(history.history[\"val_loss\"], label = \"validation loss\")\n    plt.legend()\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Binary Cross entropy\")\n\n    plt.subplot(2,2,2)\n    plt.plot(history.history[\"dice_coef\"], label = \"training dice coefficient\")\n    plt.plot(history.history[\"val_dice_coef\"], label = \"validation dice coefficient\")\n    plt.legend()\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Dice Coefficient\")\n    \nget_metrics(history = history)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T09:55:39.010401Z","iopub.execute_input":"2023-12-02T09:55:39.010805Z","iopub.status.idle":"2023-12-02T09:55:39.416410Z","shell.execute_reply.started":"2023-12-02T09:55:39.010770Z","shell.execute_reply":"2023-12-02T09:55:39.415363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#custom dataset masks extraction\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom glob import glob\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nfrom skimage import exposure\nimport cv2\nimport warnings\nwarnings.filterwarnings('ignore')\nimport shutil\nimport tensorflow as tf\n%matplotlib inline\n\nimport matplotlib.pylab as pylab\nimport seaborn as sns\nimport pprint\nimport pydicom as dicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport wandb\n\nimport PIL\nfrom PIL import Image\nfrom colorama import Fore, Back, Style\nviz_counter=0\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T10:01:45.237835Z","iopub.execute_input":"2023-12-02T10:01:45.238296Z","iopub.status.idle":"2023-12-02T10:01:46.269182Z","shell.execute_reply.started":"2023-12-02T10:01:45.238258Z","shell.execute_reply":"2023-12-02T10:01:46.267899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\nimport os\nFIND_FOLDER = r'/kaggle/input/sample/sample/sample/images'\nimages_files = glob.glob(os.path.join(FIND_FOLDER, '*.png'))\nprint(len(images_files), \"Files Found.\")","metadata":{"execution":{"iopub.status.busy":"2023-12-02T10:02:22.157423Z","iopub.execute_input":"2023-12-02T10:02:22.157819Z","iopub.status.idle":"2023-12-02T10:02:22.421979Z","shell.execute_reply.started":"2023-12-02T10:02:22.157784Z","shell.execute_reply":"2023-12-02T10:02:22.421004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subset_png_files = images_files[:2]","metadata":{"execution":{"iopub.status.busy":"2023-12-02T10:02:35.040187Z","iopub.execute_input":"2023-12-02T10:02:35.040575Z","iopub.status.idle":"2023-12-02T10:02:35.045389Z","shell.execute_reply.started":"2023-12-02T10:02:35.040544Z","shell.execute_reply":"2023-12-02T10:02:35.044248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"viz_counter=0\nimport cv2\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef props(arr):\n    print(\"Shape:\", arr.shape, \"Maximum:\", arr.max(), \"Minimum:\", arr.min(), \"Data Type:\", arr.dtype)\n\nfor path in subset_png_files:  # Change this variable to your list of PNG file paths\n    # Read PNG file\n    modified_image_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n\n    # Display properties\n    props(modified_image_data)\n\n    # Display images\n    fig, ax = plt.subplots(1, 2, figsize=(20, 12))\n    ax[0].imshow(modified_image_data, cmap=\"gray\")\n    ax[0].axis('off')\n    ax[1].imshow(modified_image_data, cmap=\"viridis\")\n    ax[1].axis('off')\n\n    # Save and show the figure\n    plt.savefig(str(viz_counter) + \".png\", dpi=300)\n    viz_counter += 1\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T10:02:46.291333Z","iopub.execute_input":"2023-12-02T10:02:46.291758Z","iopub.status.idle":"2023-12-02T10:02:56.074030Z","shell.execute_reply.started":"2023-12-02T10:02:46.291717Z","shell.execute_reply":"2023-12-02T10:02:56.072925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nimport cv2\ndef prepare_train_test_sample(df = pd.DataFrame(), resize_shape = tuple(), color_mode = \"rgb\"):\n    img_array = list()\n    #mask_array = list()\n\n    for image_path in tqdm(paths_df.image_path):\n        resized_image = cv2.resize(cv2.imread(image_path),resize_shape)\n        resized_image = resized_image/255.\n        if color_mode == \"gray\":\n            img_array.append(resized_image[:,:,0])\n        elif color_mode == \"rgb\":\n            img_array.append(resized_image[:,:,:])\n\n    return img_array\npaths_df = pd.DataFrame({'image_path': ['/kaggle/input/sample/sample/sample/images']})\n\nimg_array = prepare_train_test_sample(df = paths_df, resize_shape = (256,256), color_mode = \"gray\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T10:12:36.996987Z","iopub.execute_input":"2023-12-02T10:12:36.997407Z","iopub.status.idle":"2023-12-02T10:12:37.072770Z","shell.execute_reply.started":"2023-12-02T10:12:36.997360Z","shell.execute_reply":"2023-12-02T10:12:37.071003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nimport cv2\nimport os\nimport pandas as pd\n\ndef prepare_train_test_sample(folder_path='', resize_shape=tuple(), color_mode=\"rgb\"):\n    img_array = list()\n\n    # List all files in the folder\n    file_list = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith(('.jpg', '.png', '.jpeg'))]\n\n    for image_path in tqdm(file_list):\n        resized_image = cv2.resize(cv2.imread(image_path), resize_shape)\n        resized_image = resized_image / 255.\n        if color_mode == \"gray\":\n            img_array.append(resized_image[:, :, 0])\n        elif color_mode == \"rgb\":\n            img_array.append(resized_image[:, :, :])\n\n    return img_array\n\n# Specify the path to your folder containing images\nfolder_path = '/kaggle/input/sample/sample/sample/images/'\n\nimg_array = prepare_train_test_sample(folder_path=folder_path, resize_shape=(256, 256), color_mode=\"gray\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T10:17:27.183790Z","iopub.execute_input":"2023-12-02T10:17:27.184200Z","iopub.status.idle":"2023-12-02T10:17:27.260986Z","shell.execute_reply.started":"2023-12-02T10:17:27.184163Z","shell.execute_reply":"2023-12-02T10:17:27.258646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"viz_counter=0\nimport cv2\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef props(arr):\n    print(\"Shape:\", arr.shape, \"Maximum:\", arr.max(), \"Minimum:\", arr.min(), \"Data Type:\", arr.dtype)\n\nfor path in subset_png_files:  # Change this variable to your list of PNG file paths\n    # Read PNG file\n    modified_image_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n\n    # Display properties\n    props(modified_image_data)\n\n    # Display images\n    fig, ax = plt.subplots(1, 2, figsize=(20, 12))\n    ax[0].imshow(modified_image_data, cmap=\"gray\")\n    ax[0].axis('off')\n    ax[1].imshow(modified_image_data, cmap=\"viridis\")\n    ax[1].axis('off')\n\n    # Save and show the figure\n    plt.savefig(str(viz_counter) + \".png\", dpi=300)\n    viz_counter += 1\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T10:16:47.443114Z","iopub.execute_input":"2023-12-02T10:16:47.443493Z","iopub.status.idle":"2023-12-02T10:16:57.035584Z","shell.execute_reply.started":"2023-12-02T10:16:47.443462Z","shell.execute_reply":"2023-12-02T10:16:57.034546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras import backend as keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\n\n\ndef dice_coef(y_true, y_pred):\n    y_true_f = keras.flatten(y_true)\n    y_pred_f = keras.flatten(y_pred)\n    intersection = keras.sum(y_true_f * y_pred_f)\n    return (2. * intersection + 1) / (keras.sum(y_true_f) + keras.sum(y_pred_f) + 1)\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\ndef unet(input_size=(256,256,1)):\n    inputs = Input(input_size)\n\n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\n    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n\n    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n\n    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n\n    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n\n    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n\n    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n\n    return Model(inputs=[inputs], outputs=[conv10])","metadata":{"execution":{"iopub.status.busy":"2023-12-02T10:18:17.186410Z","iopub.execute_input":"2023-12-02T10:18:17.186810Z","iopub.status.idle":"2023-12-02T10:18:17.232538Z","shell.execute_reply.started":"2023-12-02T10:18:17.186775Z","shell.execute_reply":"2023-12-02T10:18:17.230023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = unet(input_size=(512,512,1))\nmodel.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss,\n                  metrics=[dice_coef, 'binary_accuracy'])\n#model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-02T10:18:24.573377Z","iopub.execute_input":"2023-12-02T10:18:24.573797Z","iopub.status.idle":"2023-12-02T10:18:24.830125Z","shell.execute_reply.started":"2023-12-02T10:18:24.573758Z","shell.execute_reply":"2023-12-02T10:18:24.829125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_weights_path = \"/kaggle/working/cxr_reg_weights.best.hdf5\"\n\nmodel.load_weights(model_weights_path)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T10:18:27.879425Z","iopub.execute_input":"2023-12-02T10:18:27.879829Z","iopub.status.idle":"2023-12-02T10:18:27.953921Z","shell.execute_reply.started":"2023-12-02T10:18:27.879795Z","shell.execute_reply":"2023-12-02T10:18:27.953050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\"\"\"\nShapes that you wish to resize to\n\"\"\"\nShape_X, Shape_Y = 1024,1024\n\nfor path in subset_png_files:  # Change this variable to your list of PNG file paths\n    # Read PNG file\n    modified_image_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n\n    # Resize the image\n    resized_image_data = cv2.resize(modified_image_data, (Shape_Y, Shape_X))\n\n    # Preprocess the image for prediction\n    prep_unet_input_img_1 = resized_image_data.reshape(1, Shape_X, Shape_Y, 1)\n    prep_unet_input_img = (prep_unet_input_img_1 - 127.0) / 127.0\n\n\n    # Make predictions using the model\n    pred_img = model.predict(prep_unet_input_img)\n    pred_img_preprocessed_1 = np.squeeze(pred_img)\n    pred_img_preprocessed = (pred_img_preprocessed_1 * 255 > 127).astype(np.int8)\n\n    # Apply the mask to the original image\n    res = cv2.bitwise_and(resized_image_data, resized_image_data, mask=pred_img_preprocessed)\n\n    fig, ax = plt.subplots(1, 3, figsize=(20, 12))\n    ax[0].imshow(resized_image_data, cmap=\"gray\")\n    ax[0].axis('off')\n    ax[1].imshow(pred_img_preprocessed, cmap=\"gray\")\n    ax[1].axis('off')\n    ax[2].imshow(res, cmap=\"viridis\")\n    ax[2].axis('off')\n    plt.savefig(str(viz_counter)+\".png\",dpi=300)\n    viz_counter+=1\n    cv2.imwrite(str(viz_counter)+\".png\",res)\n    viz_counter+=1\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-02T10:18:36.872247Z","iopub.execute_input":"2023-12-02T10:18:36.872629Z","iopub.status.idle":"2023-12-02T10:18:44.086091Z","shell.execute_reply.started":"2023-12-02T10:18:36.872594Z","shell.execute_reply":"2023-12-02T10:18:44.085002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\"\"\"\nShapes that you wish to resize to\n\"\"\"\nShape_X, Shape_Y = 1024,1024\nout = 'seg_masks'\n# Create the output directory if it doesn't exist\nos.makedirs(out, exist_ok=True)\n\nfor path in images_files:  # Change this variable to your list of PNG file paths\n    # Read PNG file\n    modified_image_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n\n    # Resize the image\n    resized_image_data = cv2.resize(modified_image_data, (Shape_Y, Shape_X))\n\n    # Preprocess the image for prediction\n    prep_unet_input_img_1 = resized_image_data.reshape(1, Shape_X, Shape_Y, 1)\n    prep_unet_input_img = (prep_unet_input_img_1 - 127.0) / 127.0\n\n\n    # Make predictions using the model\n    pred_img = model.predict(prep_unet_input_img)\n    pred_img_preprocessed_1 = np.squeeze(pred_img)\n    pred_img_preprocessed = (pred_img_preprocessed_1 * 255 > 127).astype(np.int8)\n\n    # Apply the mask to the original image\n    res = cv2.bitwise_and(resized_image_data, resized_image_data, mask=pred_img_preprocessed)\n\n    # Display the images\n    #fig, ax = plt.subplots(1, 2, figsize=(20, 12))\n    fig=plt.plot()\n    # ax[0].imshow(resized_image_data, cmap=\"gray\")\n    # ax[0].axis('off')\n    plt.imshow(pred_img_preprocessed,cmap='gray')\n    # ax[1].axis('off')\n    # ax[2].imshow(res, cmap=\"gray\")\n    # ax[2].axis('off')\n    plt.savefig(str(viz_counter) + \".png\", dpi=300)\n    viz_counter += 1\n    # cv2.imwrite(str(viz_counter) + \".png\", res)\n    # viz_counter += 1\n    # out='/content/segmented_masks'\n    # Save the displayed images\n    save_path = os.path.join(out, f\"{os.path.splitext(os.path.basename(path))[0]}_mask.png\")\n    plt.savefig(save_path, dpi=300)\n    cv2.imwrite(save_path, pred_img_preprocessed * 255)\n\n    # Increment the counter\n    viz_counter += 1\n    #plt.show()\n    # # Save the binary mask with the same name as the original image\n    # mask_save_path = os.path.join(output_directory, f\"{os.path.splitext(os.path.basename(path))[0]}_mask.png\")\n    # cv2.imwrite(mask_save_path, pred_img_preprocessed * 255)","metadata":{},"execution_count":null,"outputs":[]}]}