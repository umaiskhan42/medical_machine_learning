{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9999bb69",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-29T17:32:54.056838Z",
     "iopub.status.busy": "2023-12-29T17:32:54.056485Z",
     "iopub.status.idle": "2023-12-29T17:33:00.035968Z",
     "shell.execute_reply": "2023-12-29T17:33:00.034897Z"
    },
    "papermill": {
     "duration": 5.993837,
     "end_time": "2023-12-29T17:33:00.038430",
     "exception": false,
     "start_time": "2023-12-29T17:32:54.044593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# library imports \n",
    "import pdb\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "# use this seed function to make sure the result is reproducible\n",
    "def reset_seed():\n",
    "  torch.manual_seed(42)\n",
    "  random.seed(42)\n",
    "  torch.cuda.manual_seed(42)\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24c96ada",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T17:33:00.060538Z",
     "iopub.status.busy": "2023-12-29T17:33:00.060032Z",
     "iopub.status.idle": "2023-12-29T17:33:01.300327Z",
     "shell.execute_reply": "2023-12-29T17:33:01.299235Z"
    },
    "papermill": {
     "duration": 1.253645,
     "end_time": "2023-12-29T17:33:01.302492",
     "exception": false,
     "start_time": "2023-12-29T17:33:00.048847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21303 Files Found.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "FIND_FOLDER = '/kaggle/input/chest-x-rays-with-masks/CXR with masks dataset/images' # replace this with your dataset directory\n",
    "images_files = glob.glob(os.path.join(FIND_FOLDER, '*.png'))\n",
    "print(len(images_files), \"Files Found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d34786ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T17:33:01.324571Z",
     "iopub.status.busy": "2023-12-29T17:33:01.323943Z",
     "iopub.status.idle": "2023-12-29T17:39:07.552515Z",
     "shell.execute_reply": "2023-12-29T17:39:07.551586Z"
    },
    "papermill": {
     "duration": 366.241954,
     "end_time": "2023-12-29T17:39:07.554895",
     "exception": false,
     "start_time": "2023-12-29T17:33:01.312941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "# Define your directories\n",
    "base_dir = \"/kaggle/input/chest-x-rays-with-masks/CXR with masks dataset\"\n",
    "images_dir = os.path.join(base_dir, 'images')\n",
    "masks_dir = os.path.join(base_dir, 'masks')\n",
    "\n",
    "# Create new directories if they don't exist\n",
    "os.makedirs('trainimages', exist_ok=True)\n",
    "os.makedirs('trainmasks', exist_ok=True)\n",
    "os.makedirs('valimages', exist_ok=True)\n",
    "os.makedirs('valmasks', exist_ok=True)\n",
    "os.makedirs('testimages', exist_ok=True)\n",
    "os.makedirs('testmasks', exist_ok=True)\n",
    "\n",
    "# Get a list of all image and mask names\n",
    "image_names = os.listdir(images_dir)\n",
    "mask_names = os.listdir(masks_dir)\n",
    "\n",
    "# Shuffle the list of names\n",
    "np.random.shuffle(image_names)\n",
    "\n",
    "# Split the names into training, validation, and test sets (80-10-10 split)\n",
    "train_size = int(0.8 * len(image_names))\n",
    "val_size = int(0.1 * len(image_names))\n",
    "test_size = len(image_names) - train_size - val_size\n",
    "\n",
    "train_image_names = image_names[:train_size]\n",
    "val_image_names = image_names[train_size:train_size + val_size]\n",
    "test_image_names = image_names[train_size + val_size:]\n",
    "\n",
    "# Copy the images and masks into the new directories\n",
    "for name in train_image_names:\n",
    "    shutil.copy(os.path.join(images_dir, name), 'trainimages')\n",
    "    shutil.copy(os.path.join(masks_dir, name), 'trainmasks')\n",
    "\n",
    "for name in val_image_names:\n",
    "    shutil.copy(os.path.join(images_dir, name), 'valimages')\n",
    "    shutil.copy(os.path.join(masks_dir, name), 'valmasks')\n",
    "\n",
    "for name in test_image_names:\n",
    "    shutil.copy(os.path.join(images_dir, name), 'testimages')\n",
    "    shutil.copy(os.path.join(masks_dir, name), 'testmasks')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80b783d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T17:39:07.577010Z",
     "iopub.status.busy": "2023-12-29T17:39:07.576689Z",
     "iopub.status.idle": "2023-12-29T17:39:07.642794Z",
     "shell.execute_reply": "2023-12-29T17:39:07.641747Z"
    },
    "papermill": {
     "duration": 0.079573,
     "end_time": "2023-12-29T17:39:07.644959",
     "exception": false,
     "start_time": "2023-12-29T17:39:07.565386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17042 Files Found.\n"
     ]
    }
   ],
   "source": [
    "FIND_FOLDER = '/kaggle/working/trainimages'\n",
    "ch = glob.glob(os.path.join(FIND_FOLDER, '*.png'))\n",
    "print(len(ch), \"Files Found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca5136ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T17:39:07.666680Z",
     "iopub.status.busy": "2023-12-29T17:39:07.666367Z",
     "iopub.status.idle": "2023-12-29T17:39:07.700621Z",
     "shell.execute_reply": "2023-12-29T17:39:07.699809Z"
    },
    "papermill": {
     "duration": 0.04757,
     "end_time": "2023-12-29T17:39:07.702680",
     "exception": false,
     "start_time": "2023-12-29T17:39:07.655110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Medical_Dataset(Dataset):\n",
    "  def __init__(self, image_dir, mask_dir, transform=None):\n",
    "    self.image_dir = image_dir\n",
    "    self.mask_dir = mask_dir\n",
    "    self.transform = transform\n",
    "    self.images = os.listdir(image_dir)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.images)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    img_path = os.path.join(self.image_dir, self.images[index])\n",
    "    mask_path = os.path.join(self.mask_dir, self.images[index])\n",
    "    image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "    image = cv2.resize(image, (128,128))\n",
    "\n",
    "    mask = np.array(Image.open(mask_path))\n",
    "    mask=cv2.resize(mask,(128,128))\n",
    "    mask[mask >= 1] = 1.0\n",
    "\n",
    "    if self.transform is not None:\n",
    "      augmentations = self.transform(image=image, mask=mask)\n",
    "      image = augmentations[\"image\"]\n",
    "      mask = augmentations[\"mask\"]\n",
    "    return image, mask\n",
    "\n",
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=128, width=128),\n",
    "        A.Rotate(limit=35, p=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.1),\n",
    "        A.Normalize(\n",
    "            mean = [0.0, 0.0, 0.0],\n",
    "            std = [1.0, 1.0, 1.0],\n",
    "            max_pixel_value = 255.0\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "val_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=128, width=128),\n",
    "        A.Normalize(\n",
    "            mean = [0.0, 0.0, 0.0],\n",
    "            std = [1.0, 1.0, 1.0],\n",
    "            max_pixel_value = 255.0\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "TRAIN_DIR = r'/kaggle/working/trainimages'\n",
    "TRAIN_MASK = r'/kaggle/working/trainmasks'\n",
    "TEST_DIR = r'/kaggle/working/testimages'\n",
    "TEST_MASK = r'/kaggle/working/testmasks'\n",
    "VAL_DIR = r'/kaggle/working/valimages'\n",
    "VAL_MASK = r'/kaggle/working/valmasks'\n",
    "\n",
    "train_ds = Medical_Dataset(TRAIN_DIR, TRAIN_MASK, transform=train_transform)\n",
    "val_ds = Medical_Dataset(VAL_DIR, VAL_MASK, transform=val_transform)\n",
    "test_ds = Medical_Dataset(TEST_DIR, TEST_MASK, transform=val_transform)\n",
    "reset_seed()\n",
    "\n",
    "BATCH_SIZE =32\n",
    "NUM_WORKERS = 2  # add 2 or 4 if using gpu\n",
    "IMAGE_HEIGHT = 128\n",
    "IMAGE_WIDTH = 128\n",
    "PIN_MEMORY = True\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    num_workers = NUM_WORKERS,\n",
    "    pin_memory = PIN_MEMORY,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers = NUM_WORKERS,\n",
    "    pin_memory = PIN_MEMORY,\n",
    "    shuffle=False\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers = NUM_WORKERS,\n",
    "    pin_memory = PIN_MEMORY,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b980cc0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T17:39:07.724738Z",
     "iopub.status.busy": "2023-12-29T17:39:07.724151Z",
     "iopub.status.idle": "2023-12-29T17:39:07.763858Z",
     "shell.execute_reply": "2023-12-29T17:39:07.762754Z"
    },
    "papermill": {
     "duration": 0.053093,
     "end_time": "2023-12-29T17:39:07.765910",
     "exception": false,
     "start_time": "2023-12-29T17:39:07.712817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 128, 128])\n",
      "torch.Size([128, 128])\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_ds:\n",
    "  print(X.shape)\n",
    "  print(y.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcac3d45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T17:39:07.788388Z",
     "iopub.status.busy": "2023-12-29T17:39:07.788081Z",
     "iopub.status.idle": "2023-12-29T17:39:07.793403Z",
     "shell.execute_reply": "2023-12-29T17:39:07.792647Z"
    },
    "papermill": {
     "duration": 0.019076,
     "end_time": "2023-12-29T17:39:07.795279",
     "exception": false,
     "start_time": "2023-12-29T17:39:07.776203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "  return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "class qkv_transform(nn.Conv1d):\n",
    "  \"\"\"Conv1d for qkv_transform\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "252dbd0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T17:39:07.816889Z",
     "iopub.status.busy": "2023-12-29T17:39:07.816604Z",
     "iopub.status.idle": "2023-12-29T17:39:07.841716Z",
     "shell.execute_reply": "2023-12-29T17:39:07.840906Z"
    },
    "papermill": {
     "duration": 0.038382,
     "end_time": "2023-12-29T17:39:07.843667",
     "exception": false,
     "start_time": "2023-12-29T17:39:07.805285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AxialAttention(nn.Module):\n",
    "  \n",
    "  def __init__(self,\n",
    "               in_planes,\n",
    "               out_planes,\n",
    "               groups=8,\n",
    "               kernel_size=56,\n",
    "               stride=1,\n",
    "               bias=False,\n",
    "               width=False):\n",
    "    \"\"\"\n",
    "    args :\n",
    "      in_planes : d_q\n",
    "      out_planes : d_out\n",
    "      groups : number heads \n",
    "      kernel_size : size of memory block\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    self.in_planes = in_planes\n",
    "    self.out_planes = out_planes\n",
    "    self.groups = groups\n",
    "    self.group_planes = out_planes // groups\n",
    "    self.kernel_size = kernel_size\n",
    "    self.stride = stride\n",
    "    self.bias = bias\n",
    "    self.width = width\n",
    "\n",
    "    # Multi-head self attention\n",
    "    # d_q = out_planes // 2, d_out = out_planes (out_planes = 16) => number of \n",
    "    self.qkv_transform = qkv_transform(in_planes, out_planes*2, kernel_size=1, stride=1,\n",
    "                                       padding=0, bias=False)\n",
    "    self.bn_qkv = nn.BatchNorm1d(out_planes * 2) # shape : q,k : (out_planes, d_q)\n",
    "    self.bn_similarity = nn.BatchNorm2d(groups * 3)\n",
    "    self.bn_output = nn.BatchNorm1d(out_planes * 2)\n",
    "\n",
    "    # position embedding\n",
    "    # (2 * kernel_size - 1) position : -(kernel_size-1),...,0,...,(kernel_size-1)\n",
    "    # number of channels = channels of r_q + channels of r_k + channels of r_v\n",
    "    # group_planes * 2   =  group_planes//2 * 2 + group_planes (dim value + dim query + dim key)\n",
    "    # => dim of embedding position : group_planes * 2 * (kernel_size * 2 - 1)\n",
    "    self.relative = nn.Parameter(torch.randn(self.group_planes * 2, kernel_size * 2 - 1), requires_grad=True)\n",
    "    query_index = torch.arange(kernel_size).unsqueeze(0)\n",
    "    key_index = torch.arange(kernel_size).unsqueeze(1)\n",
    "    relative_index = key_index - query_index + kernel_size - 1\n",
    "    self.register_buffer('flatten_index', relative_index.view(-1))\n",
    "    if stride > 1:\n",
    "      self.pooling = nn.AvgPool2d(stride, stride=stride)\n",
    "    \n",
    "    self.reset_paremeters()\n",
    "  \n",
    "  def forward(self, x):\n",
    "    # axial attention width-axis \n",
    "    if self.width:\n",
    "      x = x.permute(0, 2, 1, 3) # N, H, C, W\n",
    "    else:\n",
    "      x = x.permute(0, 3, 1, 2) # N, W, C, H\n",
    "    N, W, C, H = x.shape\n",
    "    x = x.contiguous().view(N*W, C, H)\n",
    "    # Transformations\n",
    "    qkv = self.bn_qkv(self.qkv_transform(x))\n",
    "    #print(x.shape)\n",
    "    #print(self.qkv_transform(x).shape)\n",
    "    q, k, v = torch.split(qkv.reshape(N*W, self.groups, self.group_planes * 2, H), \n",
    "                          [self.group_planes // 2, self.group_planes // 2, self.group_planes], dim=2)\n",
    "    \n",
    "    # Calculate position embedding\n",
    "    # self.flatten_index : shape (kernel_size * kernel_size)\n",
    "    all_embedding = torch.index_select(self.relative, 1, self.flatten_index).view(self.group_planes * 2, self.kernel_size, self.kernel_size)\n",
    "    q_embedding, k_embedding, v_embedding = torch.split(all_embedding, [self.group_planes // 2, self.group_planes // 2, self.group_planes], dim=0)\n",
    "    qqn = q_embedding[0].detach().cpu().numpy()\n",
    "    #plt.imshow(qqn)\n",
    "    kqn = k_embedding[0].detach().cpu().numpy()\n",
    "    #plt.imshow(kqn)\n",
    "    # q : shape (N*W, number heads, self.group_planes // 2 = d_q, H)\n",
    "    # k : shape (N*W, number heads, self.group_planes // 2 = d_q, H)\n",
    "    # v : shape (N*W, number heads, self.group_planes = 2 * d_q, H)\n",
    "    # q_embedding : shape (self.group_planes // 2, kernel_size, kernel_size)\n",
    "    # k_embedding : shape (self.group_planes // 2, kernel_size, kernel_size)\n",
    "    # v_embedding : shape (self.group_planes, kernel_size, kernel_size)\n",
    "    # qr : shape (N*W, number heads, kernel_size, kernel_size)\n",
    "    # kr : shape (N*W, number heads, kernel_size, kernel_size)\n",
    "    # why transpose(2, 3) -> because index of equal (2) Medical-Transform\n",
    "    # qk : shape\n",
    "    qr = torch.einsum('bgci,cij->bgij', q, q_embedding)\n",
    "    kr = torch.einsum('bgci,cij->bgij', k, k_embedding).transpose(2, 3)\n",
    "    qk = torch.einsum('bgci,bgcj->bgij', q, k)\n",
    "    # batchnorm each qr, qk, kr before sum\n",
    "    stacked_similarity = torch.cat([qk, qr, kr], dim=1)\n",
    "    stacked_similarity = self.bn_similarity(stacked_similarity).view(N*W, 3, self.groups, H, H).sum(dim=1)\n",
    "    # stacked_similarity = self.bn_qr(qr) + self.bn_kr(kr) + self.bn_qk(qk)\n",
    "    # (N*W, groups, H, H)\n",
    "    similarity = F.softmax(stacked_similarity, dim=3)\n",
    "    sv = torch.einsum('bgij,bgcj->bgci', similarity, v)\n",
    "    sve = torch.einsum('bgij,cij->bgci', similarity, v_embedding)\n",
    "    stacked_output = torch.cat([sv, sve], dim=-1).view(N*W, self.out_planes*2, H)\n",
    "    output = self.bn_output(stacked_output).view(N, W, self.out_planes, 2, H).sum(dim=-2)\n",
    "\n",
    "    if self.width:\n",
    "      output = output.permute(0, 2, 1, 3)\n",
    "    else:\n",
    "      output = output.permute(0, 2, 3, 1)\n",
    "    \n",
    "    if self.stride > 1:\n",
    "      output = self.pooling(output)\n",
    "    return output\n",
    "\n",
    "  def reset_paremeters(self):\n",
    "    self.qkv_transform.weight.data.normal_(0, math.sqrt(1. / self.in_planes))\n",
    "    nn.init.normal_(self.relative, 0, math.sqrt(1. / self.group_planes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e6056fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T17:39:07.865621Z",
     "iopub.status.busy": "2023-12-29T17:39:07.865297Z",
     "iopub.status.idle": "2023-12-29T17:39:07.886892Z",
     "shell.execute_reply": "2023-12-29T17:39:07.886014Z"
    },
    "papermill": {
     "duration": 0.034853,
     "end_time": "2023-12-29T17:39:07.888743",
     "exception": false,
     "start_time": "2023-12-29T17:39:07.853890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AxialAttention_dynamic(nn.Module):\n",
    "  def __init__(self, \n",
    "               in_planes, \n",
    "               out_planes, \n",
    "               groups=8, \n",
    "               kernel_size=56,\n",
    "               stride=1, \n",
    "               bias=False, \n",
    "               width=False):\n",
    "      assert (in_planes % groups == 0) and (out_planes % groups == 0)\n",
    "      super(AxialAttention_dynamic, self).__init__()\n",
    "      self.in_planes = in_planes\n",
    "      self.out_planes = out_planes\n",
    "      self.groups = groups\n",
    "      self.group_planes = out_planes // groups\n",
    "      self.kernel_size = kernel_size\n",
    "      self.stride = stride\n",
    "      self.bias = bias\n",
    "      self.width = width\n",
    "\n",
    "      # Multi-head self attention\n",
    "      self.qkv_transform = qkv_transform(in_planes, out_planes * 2, kernel_size=1, stride=1,\n",
    "                                          padding=0, bias=False)\n",
    "      self.bn_qkv = nn.BatchNorm1d(out_planes * 2)\n",
    "      self.bn_similarity = nn.BatchNorm2d(groups * 3)\n",
    "      self.bn_output = nn.BatchNorm1d(out_planes * 2)\n",
    "\n",
    "      # Priority on encoding\n",
    "\n",
    "      ## Initial values \n",
    "\n",
    "      self.f_qr = nn.Parameter(torch.tensor(0.1),  requires_grad=False) \n",
    "      self.f_kr = nn.Parameter(torch.tensor(0.1),  requires_grad=False)\n",
    "      self.f_sve = nn.Parameter(torch.tensor(0.1),  requires_grad=False)\n",
    "      self.f_sv = nn.Parameter(torch.tensor(1.0),  requires_grad=False)\n",
    "\n",
    "\n",
    "      # Position embedding\n",
    "      self.relative = nn.Parameter(torch.randn(self.group_planes * 2, kernel_size * 2 - 1), requires_grad=True)\n",
    "      query_index = torch.arange(kernel_size).unsqueeze(0)\n",
    "      key_index = torch.arange(kernel_size).unsqueeze(1)\n",
    "      relative_index = key_index - query_index + kernel_size - 1\n",
    "      self.register_buffer('flatten_index', relative_index.view(-1))\n",
    "      if stride > 1:\n",
    "          self.pooling = nn.AvgPool2d(stride, stride=stride)\n",
    "\n",
    "      self.reset_parameters()\n",
    "      # self.print_para()\n",
    "\n",
    "  def forward(self, x):\n",
    "      if self.width:\n",
    "          x = x.permute(0, 2, 1, 3)\n",
    "      else:\n",
    "          x = x.permute(0, 3, 1, 2)  # N, W, C, H\n",
    "      N, W, C, H = x.shape\n",
    "      x = x.contiguous().view(N * W, C, H)\n",
    "\n",
    "      # Transformations\n",
    "      qkv = self.bn_qkv(self.qkv_transform(x))\n",
    "      q, k, v = torch.split(qkv.reshape(N * W, self.groups, self.group_planes * 2, H), [self.group_planes // 2, self.group_planes // 2, self.group_planes], dim=2)\n",
    "\n",
    "      # Calculate position embedding\n",
    "      all_embeddings = torch.index_select(self.relative, 1, self.flatten_index).view(self.group_planes * 2, self.kernel_size, self.kernel_size)\n",
    "      q_embedding, k_embedding, v_embedding = torch.split(all_embeddings, [self.group_planes // 2, self.group_planes // 2, self.group_planes], dim=0)\n",
    "      qr = torch.einsum('bgci,cij->bgij', q, q_embedding)\n",
    "      kr = torch.einsum('bgci,cij->bgij', k, k_embedding).transpose(2, 3)\n",
    "      qk = torch.einsum('bgci, bgcj->bgij', q, k)\n",
    "\n",
    "\n",
    "      # multiply by factors\n",
    "      qr = torch.mul(qr, self.f_qr)\n",
    "      kr = torch.mul(kr, self.f_kr)\n",
    "\n",
    "      stacked_similarity = torch.cat([qk, qr, kr], dim=1)\n",
    "      stacked_similarity = self.bn_similarity(stacked_similarity).view(N * W, 3, self.groups, H, H).sum(dim=1)\n",
    "      #stacked_similarity = self.bn_qr(qr) + self.bn_kr(kr) + self.bn_qk(qk)\n",
    "      # (N, groups, H, H, W)\n",
    "      similarity = F.softmax(stacked_similarity, dim=3)\n",
    "      sv = torch.einsum('bgij,bgcj->bgci', similarity, v)\n",
    "      sve = torch.einsum('bgij,cij->bgci', similarity, v_embedding)\n",
    "\n",
    "      # multiply by factors\n",
    "      sv = torch.mul(sv, self.f_sv)\n",
    "      sve = torch.mul(sve, self.f_sve)\n",
    "\n",
    "      stacked_output = torch.cat([sv, sve], dim=-1).view(N * W, self.out_planes * 2, H)\n",
    "      output = self.bn_output(stacked_output).view(N, W, self.out_planes, 2, H).sum(dim=-2)\n",
    "\n",
    "      if self.width:\n",
    "          output = output.permute(0, 2, 1, 3)\n",
    "      else:\n",
    "          output = output.permute(0, 2, 3, 1)\n",
    "\n",
    "      if self.stride > 1:\n",
    "          output = self.pooling(output)\n",
    "\n",
    "      return output\n",
    "  def reset_parameters(self):\n",
    "      self.qkv_transform.weight.data.normal_(0, math.sqrt(1. / self.in_planes))\n",
    "      #nn.init.uniform_(self.relative, -0.1, 0.1)\n",
    "      nn.init.normal_(self.relative, 0., math.sqrt(1. / self.group_planes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f60259a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T17:39:07.910078Z",
     "iopub.status.busy": "2023-12-29T17:39:07.909723Z",
     "iopub.status.idle": "2023-12-29T17:39:07.924322Z",
     "shell.execute_reply": "2023-12-29T17:39:07.923598Z"
    },
    "papermill": {
     "duration": 0.027381,
     "end_time": "2023-12-29T17:39:07.926128",
     "exception": false,
     "start_time": "2023-12-29T17:39:07.898747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AxialAttention_wopos(nn.Module):\n",
    "  def __init__(self, in_planes, out_planes, groups=8, kernel_size=56,\n",
    "                stride=1, bias=False, width=False):\n",
    "      assert (in_planes % groups == 0) and (out_planes % groups == 0)\n",
    "      super(AxialAttention_wopos, self).__init__()\n",
    "      self.in_planes = in_planes\n",
    "      self.out_planes = out_planes\n",
    "      self.groups = groups\n",
    "      self.group_planes = out_planes // groups\n",
    "      self.kernel_size = kernel_size\n",
    "      self.stride = stride\n",
    "      self.bias = bias\n",
    "      self.width = width\n",
    "\n",
    "      # Multi-head self attention\n",
    "      self.qkv_transform = qkv_transform(in_planes, out_planes * 2, kernel_size=1, stride=1,\n",
    "                                          padding=0, bias=False)\n",
    "      self.bn_qkv = nn.BatchNorm1d(out_planes * 2)\n",
    "      self.bn_similarity = nn.BatchNorm2d(groups )\n",
    "\n",
    "      self.bn_output = nn.BatchNorm1d(out_planes * 1)\n",
    "\n",
    "      if stride > 1:\n",
    "          self.pooling = nn.AvgPool2d(stride, stride=stride)\n",
    "\n",
    "      self.reset_parameters()\n",
    "\n",
    "  def forward(self, x):\n",
    "      if self.width:\n",
    "          x = x.permute(0, 2, 1, 3)\n",
    "      else:\n",
    "          x = x.permute(0, 3, 1, 2)  # N, W, C, H\n",
    "      N, W, C, H = x.shape\n",
    "      x = x.contiguous().view(N * W, C, H)\n",
    "\n",
    "      # Transformations\n",
    "      qkv = self.bn_qkv(self.qkv_transform(x))\n",
    "      q, k, v = torch.split(qkv.reshape(N * W, self.groups, self.group_planes * 2, H), [self.group_planes // 2, self.group_planes // 2, self.group_planes], dim=2)\n",
    "\n",
    "      qk = torch.einsum('bgci, bgcj->bgij', q, k)\n",
    "\n",
    "      stacked_similarity = self.bn_similarity(qk).reshape(N * W, 1, self.groups, H, H).sum(dim=1).contiguous()\n",
    "\n",
    "      similarity = F.softmax(stacked_similarity, dim=3)\n",
    "      sv = torch.einsum('bgij,bgcj->bgci', similarity, v)\n",
    "\n",
    "      sv = sv.reshape(N*W,self.out_planes * 1, H).contiguous()\n",
    "      output = self.bn_output(sv).reshape(N, W, self.out_planes, 1, H).sum(dim=-2).contiguous()\n",
    "\n",
    "\n",
    "      if self.width:\n",
    "          output = output.permute(0, 2, 1, 3)\n",
    "      else:\n",
    "          output = output.permute(0, 2, 3, 1)\n",
    "\n",
    "      if self.stride > 1:\n",
    "          output = self.pooling(output)\n",
    "\n",
    "      return output\n",
    "\n",
    "  def reset_parameters(self):\n",
    "      self.qkv_transform.weight.data.normal_(0, math.sqrt(1. / self.in_planes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8996a4ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T17:39:07.947269Z",
     "iopub.status.busy": "2023-12-29T17:39:07.946928Z",
     "iopub.status.idle": "2023-12-29T17:39:07.957442Z",
     "shell.execute_reply": "2023-12-29T17:39:07.956734Z"
    },
    "papermill": {
     "duration": 0.023342,
     "end_time": "2023-12-29T17:39:07.959366",
     "exception": false,
     "start_time": "2023-12-29T17:39:07.936024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AxialBlock(nn.Module):\n",
    "  expansion = 2\n",
    "\n",
    "  def __init__(self, \n",
    "               inplanes, \n",
    "               planes, \n",
    "               stride=1, \n",
    "               downsample=None, \n",
    "               groups=1,\n",
    "               base_width=64,\n",
    "               dilation=1,\n",
    "               norm_layer=None,\n",
    "               kernel_size=56):\n",
    "    super().__init__()\n",
    "    if norm_layer is None:\n",
    "      norm_layer = nn.BatchNorm2d\n",
    "    width = int(planes * (base_width / 64.))\n",
    "    # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "    self.groups = groups\n",
    "    self.conv_down = conv1x1(inplanes, width)\n",
    "    self.bn1 = norm_layer(width)\n",
    "    self.hight_block = AxialAttention(width, width, groups=groups, kernel_size=kernel_size)\n",
    "    self.width_block = AxialAttention(width, width, groups=groups, kernel_size=kernel_size, width=True)\n",
    "    self.conv_up = conv1x1(width, planes*self.expansion)\n",
    "    self.bn2 = norm_layer(planes * self.expansion)\n",
    "    self.relu = nn.ReLU(inplace=True)\n",
    "    self.downsample = downsample\n",
    "    self.stride = stride\n",
    "\n",
    "  def forward(self, x):\n",
    "    identity = x\n",
    "\n",
    "    out = self.conv_down(x)\n",
    "    out = self.bn1(out)\n",
    "    out = self.relu(out)\n",
    "    \n",
    "    out = self.hight_block(out)\n",
    "    out = self.width_block(out)\n",
    "    out = self.relu(out)\n",
    "\n",
    "    out = self.conv_up(out)\n",
    "    out = self.bn2(out)\n",
    "\n",
    "    if self.downsample is not None:\n",
    "      identity = self.downsample(x)\n",
    "    \n",
    "    out += identity\n",
    "    out = self.relu(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1bbf897",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T17:39:07.981044Z",
     "iopub.status.busy": "2023-12-29T17:39:07.980472Z",
     "iopub.status.idle": "2023-12-29T17:39:07.990473Z",
     "shell.execute_reply": "2023-12-29T17:39:07.989640Z"
    },
    "papermill": {
     "duration": 0.022932,
     "end_time": "2023-12-29T17:39:07.992379",
     "exception": false,
     "start_time": "2023-12-29T17:39:07.969447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AxialBlock_dynamic(nn.Module):\n",
    "  expansion = 2\n",
    "\n",
    "  def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                base_width=64, dilation=1, norm_layer=None, kernel_size=56):\n",
    "      super(AxialBlock_dynamic, self).__init__()\n",
    "      if norm_layer is None:\n",
    "          norm_layer = nn.BatchNorm2d\n",
    "      width = int(planes * (base_width / 64.))\n",
    "      # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "      self.conv_down = conv1x1(inplanes, width)\n",
    "      self.bn1 = norm_layer(width)\n",
    "      self.hight_block = AxialAttention_dynamic(width, width, groups=groups, kernel_size=kernel_size)\n",
    "      self.width_block = AxialAttention_dynamic(width, width, groups=groups, kernel_size=kernel_size, stride=stride, width=True)\n",
    "      self.conv_up = conv1x1(width, planes * self.expansion)\n",
    "      self.bn2 = norm_layer(planes * self.expansion)\n",
    "      self.relu = nn.ReLU(inplace=True)\n",
    "      self.downsample = downsample\n",
    "      self.stride = stride\n",
    "\n",
    "  def forward(self, x):\n",
    "      identity = x\n",
    "\n",
    "      out = self.conv_down(x)\n",
    "      out = self.bn1(out)\n",
    "      out = self.relu(out)\n",
    "\n",
    "      out = self.hight_block(out)\n",
    "      out = self.width_block(out)\n",
    "      out = self.relu(out)\n",
    "\n",
    "      out = self.conv_up(out)\n",
    "      out = self.bn2(out)\n",
    "\n",
    "      if self.downsample is not None:\n",
    "          identity = self.downsample(x)\n",
    "      #print(out.shape)\n",
    "      #print(identity.shape)\n",
    "      out += identity\n",
    "      out = self.relu(out)\n",
    "\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08d9c3ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T17:39:08.013686Z",
     "iopub.status.busy": "2023-12-29T17:39:08.013405Z",
     "iopub.status.idle": "2023-12-29T17:39:08.024120Z",
     "shell.execute_reply": "2023-12-29T17:39:08.023400Z"
    },
    "papermill": {
     "duration": 0.023733,
     "end_time": "2023-12-29T17:39:08.026082",
     "exception": false,
     "start_time": "2023-12-29T17:39:08.002349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AxialBlock_wopos(nn.Module):\n",
    "  expansion = 2\n",
    "\n",
    "  def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                base_width=64, dilation=1, norm_layer=None, kernel_size=56):\n",
    "      super(AxialBlock_wopos, self).__init__()\n",
    "      if norm_layer is None:\n",
    "          norm_layer = nn.BatchNorm2d\n",
    "      # print(kernel_size)\n",
    "      width = int(planes * (base_width / 64.))\n",
    "      # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "      self.conv_down = conv1x1(inplanes, width)\n",
    "      self.conv1 = nn.Conv2d(width, width, kernel_size = 1)\n",
    "      self.bn1 = norm_layer(width)\n",
    "      self.hight_block = AxialAttention_wopos(width, width, groups=groups, kernel_size=kernel_size)\n",
    "      self.width_block = AxialAttention_wopos(width, width, groups=groups, kernel_size=kernel_size, stride=stride, width=True)\n",
    "      self.conv_up = conv1x1(width, planes * self.expansion)\n",
    "      self.bn2 = norm_layer(planes * self.expansion)\n",
    "      self.relu = nn.ReLU(inplace=True)\n",
    "      self.downsample = downsample\n",
    "      self.stride = stride\n",
    "\n",
    "  def forward(self, x):\n",
    "      identity = x\n",
    "\n",
    "      # pdb.set_trace()\n",
    "\n",
    "      out = self.conv_down(x)\n",
    "      out = self.bn1(out)\n",
    "      out = self.relu(out)\n",
    "      # print(out.shape)\n",
    "      out = self.hight_block(out)\n",
    "      out = self.width_block(out)\n",
    "\n",
    "      out = self.relu(out)\n",
    "\n",
    "      out = self.conv_up(out)\n",
    "      out = self.bn2(out)\n",
    "\n",
    "      if self.downsample is not None:\n",
    "          identity = self.downsample(x)\n",
    "\n",
    "      out += identity\n",
    "      out = self.relu(out)\n",
    "\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b36a20c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T17:39:08.047567Z",
     "iopub.status.busy": "2023-12-29T17:39:08.047276Z",
     "iopub.status.idle": "2023-12-29T17:39:08.073554Z",
     "shell.execute_reply": "2023-12-29T17:39:08.072672Z"
    },
    "papermill": {
     "duration": 0.039333,
     "end_time": "2023-12-29T17:39:08.075415",
     "exception": false,
     "start_time": "2023-12-29T17:39:08.036082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResAxialAttentionUNet(nn.Module):\n",
    "\n",
    "  def __init__(self, block, layers, num_classes=2, zero_init_residual=True,\n",
    "                groups=8, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                norm_layer=None, s=0.125, img_size = 128,imgchan = 3):\n",
    "      super(ResAxialAttentionUNet, self).__init__()\n",
    "      if norm_layer is None:\n",
    "          norm_layer = nn.BatchNorm2d\n",
    "      self._norm_layer = norm_layer\n",
    "\n",
    "      self.inplanes = int(64 * s)\n",
    "      self.dilation = 1\n",
    "      if replace_stride_with_dilation is None:\n",
    "          replace_stride_with_dilation = [False, False, False]\n",
    "      if len(replace_stride_with_dilation) != 3:\n",
    "          raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                            \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "      self.groups = groups\n",
    "      self.base_width = width_per_group\n",
    "      self.conv1 = nn.Conv2d(imgchan, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                              bias=False)\n",
    "      self.conv2 = nn.Conv2d(self.inplanes, 128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "      self.conv3 = nn.Conv2d(128, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "      self.bn1 = norm_layer(self.inplanes)\n",
    "      self.bn2 = norm_layer(128)\n",
    "      self.bn3 = norm_layer(self.inplanes)\n",
    "      self.relu = nn.ReLU(inplace=True)\n",
    "      # self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "      self.layer1 = self._make_layer(block, int(128 * s), layers[0], kernel_size= (img_size//2))\n",
    "      self.layer2 = self._make_layer(block, int(256 * s), layers[1], stride=2, kernel_size=(img_size//2),\n",
    "                                      dilate=replace_stride_with_dilation[0])\n",
    "      self.layer3 = self._make_layer(block, int(512 * s), layers[2], stride=2, kernel_size=(img_size//4),\n",
    "                                      dilate=replace_stride_with_dilation[1])\n",
    "      self.layer4 = self._make_layer(block, int(1024 * s), layers[3], stride=2, kernel_size=(img_size//8),\n",
    "                                      dilate=replace_stride_with_dilation[2])\n",
    "      \n",
    "      # Decoder\n",
    "      self.decoder1 = nn.Conv2d(int(1024 *2*s)      ,        int(1024*2*s), kernel_size=3, stride=2, padding=1)\n",
    "      self.decoder2 = nn.Conv2d(int(1024  *2*s)     , int(1024*s), kernel_size=3, stride=1, padding=1)\n",
    "      self.decoder3 = nn.Conv2d(int(1024*s),  int(512*s), kernel_size=3, stride=1, padding=1)\n",
    "      self.decoder4 = nn.Conv2d(int(512*s) ,  int(256*s), kernel_size=3, stride=1, padding=1)\n",
    "      self.decoder5 = nn.Conv2d(int(256*s) , int(128*s) , kernel_size=3, stride=1, padding=1)\n",
    "      self.adjust   = nn.Conv2d(int(128*s) , num_classes, kernel_size=1, stride=1, padding=0)\n",
    "      self.soft     = nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "  def _make_layer(self, block, planes, blocks, kernel_size=56, stride=1, dilate=False):\n",
    "      norm_layer = self._norm_layer\n",
    "      downsample = None\n",
    "      previous_dilation = self.dilation\n",
    "      if dilate:\n",
    "          self.dilation *= stride\n",
    "          stride = 1\n",
    "      if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "          downsample = nn.Sequential(\n",
    "              conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "              norm_layer(planes * block.expansion),\n",
    "          )\n",
    "\n",
    "      layers = []\n",
    "      layers.append(block(self.inplanes, planes, stride, downsample, groups=self.groups,\n",
    "                          base_width=self.base_width, dilation=previous_dilation, \n",
    "                          norm_layer=norm_layer, kernel_size=kernel_size))\n",
    "      self.inplanes = planes * block.expansion\n",
    "      if stride != 1:\n",
    "          kernel_size = kernel_size // 2\n",
    "\n",
    "      for _ in range(1, blocks):\n",
    "          layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                              base_width=self.base_width, dilation=self.dilation,\n",
    "                              norm_layer=norm_layer, kernel_size=kernel_size))\n",
    "\n",
    "      return nn.Sequential(*layers)\n",
    "\n",
    "  def _forward_impl(self, x):\n",
    "      \n",
    "      # AxialAttention Encoder\n",
    "      # pdb.set_trace()\n",
    "      x = self.conv1(x)\n",
    "      x = self.bn1(x)\n",
    "      x = self.relu(x)\n",
    "      x = self.conv2(x)\n",
    "      x = self.bn2(x)\n",
    "      x = self.relu(x)\n",
    "      x = self.conv3(x)\n",
    "      x = self.bn3(x)\n",
    "      x = self.relu(x)\n",
    "      #print(x.shape)\n",
    "      x1 = self.layer1(x)\n",
    "      #print(x.shape)\n",
    "      x2 = self.layer2(x1)\n",
    "      # print(x2.shape)\n",
    "      x3 = self.layer3(x2)\n",
    "      # print(x3.shape)\n",
    "      x4 = self.layer4(x3)\n",
    "\n",
    "      x = F.relu(F.interpolate(self.decoder1(x4), scale_factor=(2,2), mode ='bilinear'))\n",
    "      x = torch.add(x, x4)\n",
    "      x = F.relu(F.interpolate(self.decoder2(x) , scale_factor=(2,2), mode ='bilinear'))\n",
    "      x = torch.add(x, x3)\n",
    "      x = F.relu(F.interpolate(self.decoder3(x) , scale_factor=(2,2), mode ='bilinear'))\n",
    "      x = torch.add(x, x2)\n",
    "      x = F.relu(F.interpolate(self.decoder4(x) , scale_factor=(2,2), mode ='bilinear'))\n",
    "      x = torch.add(x, x1)\n",
    "      x = F.relu(F.interpolate(self.decoder5(x) , scale_factor=(2,2), mode ='bilinear'))\n",
    "      x = self.adjust(F.relu(x))\n",
    "      # pdb.set_trace()\n",
    "      return x\n",
    "\n",
    "  def forward(self, x):\n",
    "      return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c589f4e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T17:39:08.097441Z",
     "iopub.status.busy": "2023-12-29T17:39:08.097146Z",
     "iopub.status.idle": "2023-12-29T17:39:08.137380Z",
     "shell.execute_reply": "2023-12-29T17:39:08.136556Z"
    },
    "papermill": {
     "duration": 0.053502,
     "end_time": "2023-12-29T17:39:08.139336",
     "exception": false,
     "start_time": "2023-12-29T17:39:08.085834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class medt_net(nn.Module):\n",
    "\n",
    "  def __init__(self, block, block_2, layers, num_classes=2, zero_init_residual=True,\n",
    "              groups=8, width_per_group=64, replace_stride_with_dilation=None,\n",
    "              norm_layer=None, s=0.125, img_size = 128,imgchan = 3):\n",
    "    super(medt_net, self).__init__()\n",
    "    if norm_layer is None:\n",
    "        norm_layer = nn.BatchNorm2d\n",
    "    self._norm_layer = norm_layer\n",
    "\n",
    "    self.inplanes = int(64 * s)\n",
    "    self.dilation = 1\n",
    "    if replace_stride_with_dilation is None:\n",
    "        replace_stride_with_dilation = [False, False, False]\n",
    "    if len(replace_stride_with_dilation) != 3:\n",
    "        raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                          \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "    self.groups = groups\n",
    "    self.base_width = width_per_group\n",
    "    self.conv1 = nn.Conv2d(imgchan, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                            bias=False)\n",
    "    self.conv2 = nn.Conv2d(self.inplanes, 128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.conv3 = nn.Conv2d(128, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.bn1 = norm_layer(self.inplanes)\n",
    "    self.bn2 = norm_layer(128)\n",
    "    self.bn3 = norm_layer(self.inplanes)\n",
    "    # self.conv1 = nn.Conv2d(1, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.bn1 = norm_layer(self.inplanes)\n",
    "    self.relu = nn.ReLU(inplace=True)\n",
    "    # self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "    self.layer1 = self._make_layer(block, int(128 * s), layers[0], kernel_size= (img_size//2))\n",
    "    self.layer2 = self._make_layer(block, int(256 * s), layers[1], stride=2, kernel_size=(img_size//2),\n",
    "                                    dilate=replace_stride_with_dilation[0])\n",
    "    # self.layer3 = self._make_layer(block, int(512 * s), layers[2], stride=2, kernel_size=(img_size//4),\n",
    "    #                                dilate=replace_stride_with_dilation[1])\n",
    "    # self.layer4 = self._make_layer(block, int(1024 * s), layers[3], stride=2, kernel_size=(img_size//8),\n",
    "    #                                dilate=replace_stride_with_dilation[2])\n",
    "    \n",
    "    # Decoder\n",
    "    # self.decoder1 = nn.Conv2d(int(1024 *2*s)      ,        int(1024*2*s), kernel_size=3, stride=2, padding=1)\n",
    "    # self.decoder2 = nn.Conv2d(int(1024  *2*s)     , int(1024*s), kernel_size=3, stride=1, padding=1)\n",
    "    # self.decoder3 = nn.Conv2d(int(1024*s),  int(512*s), kernel_size=3, stride=1, padding=1)\n",
    "    self.decoder4 = nn.Conv2d(int(512*s) ,  int(256*s), kernel_size=3, stride=1, padding=1)\n",
    "    self.decoder5 = nn.Conv2d(int(256*s) , int(128*s) , kernel_size=3, stride=1, padding=1)\n",
    "    self.adjust   = nn.Conv2d(int(128*s) , num_classes, kernel_size=1, stride=1, padding=0)\n",
    "    self.soft     = nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "    self.conv1_p = nn.Conv2d(imgchan, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                            bias=False)\n",
    "    self.conv2_p = nn.Conv2d(self.inplanes,128, kernel_size=3, stride=1, padding=1,\n",
    "                            bias=False)\n",
    "    self.conv3_p = nn.Conv2d(128, self.inplanes, kernel_size=3, stride=1, padding=1,\n",
    "                            bias=False)\n",
    "    # self.conv1 = nn.Conv2d(1, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.bn1_p = norm_layer(self.inplanes)\n",
    "    self.bn2_p = norm_layer(128)\n",
    "    self.bn3_p = norm_layer(self.inplanes)\n",
    "\n",
    "    self.relu_p = nn.ReLU(inplace=True)\n",
    "\n",
    "    img_size_p = img_size // 4\n",
    "\n",
    "    self.layer1_p = self._make_layer(block_2, int(128 * s), layers[0], kernel_size= (img_size_p//2))\n",
    "    self.layer2_p = self._make_layer(block_2, int(256 * s), layers[1], stride=2, kernel_size=(img_size_p//2),\n",
    "                                    dilate=replace_stride_with_dilation[0])\n",
    "    self.layer3_p = self._make_layer(block_2, int(512 * s), layers[2], stride=2, kernel_size=(img_size_p//4),\n",
    "                                    dilate=replace_stride_with_dilation[1])\n",
    "    self.layer4_p = self._make_layer(block_2, int(1024 * s), layers[3], stride=2, kernel_size=(img_size_p//8),\n",
    "                                    dilate=replace_stride_with_dilation[2])\n",
    "    \n",
    "    # Decoder\n",
    "    self.decoder1_p = nn.Conv2d(int(1024 *2*s)      ,        int(1024*2*s), kernel_size=3, stride=2, padding=1)\n",
    "    self.decoder2_p = nn.Conv2d(int(1024  *2*s)     , int(1024*s), kernel_size=3, stride=1, padding=1)\n",
    "    self.decoder3_p = nn.Conv2d(int(1024*s),  int(512*s), kernel_size=3, stride=1, padding=1)\n",
    "    self.decoder4_p = nn.Conv2d(int(512*s) ,  int(256*s), kernel_size=3, stride=1, padding=1)\n",
    "    self.decoder5_p = nn.Conv2d(int(256*s) , int(128*s) , kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    self.decoderf = nn.Conv2d(int(128*s) , int(128*s) , kernel_size=3, stride=1, padding=1)\n",
    "    self.adjust_p   = nn.Conv2d(int(128*s) , num_classes, kernel_size=1, stride=1, padding=0)\n",
    "    self.soft_p     = nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "  def _make_layer(self, block, planes, blocks, kernel_size=56, stride=1, dilate=False):\n",
    "    norm_layer = self._norm_layer\n",
    "    downsample = None\n",
    "    previous_dilation = self.dilation\n",
    "    if dilate:\n",
    "        self.dilation *= stride\n",
    "        stride = 1\n",
    "    if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "        downsample = nn.Sequential(\n",
    "            conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "            norm_layer(planes * block.expansion),\n",
    "        )\n",
    "\n",
    "    layers = []\n",
    "    layers.append(block(self.inplanes, planes, stride, downsample, groups=self.groups,\n",
    "                        base_width=self.base_width, dilation=previous_dilation, \n",
    "                        norm_layer=norm_layer, kernel_size=kernel_size))\n",
    "    self.inplanes = planes * block.expansion\n",
    "    if stride != 1:\n",
    "        kernel_size = kernel_size // 2\n",
    "\n",
    "    for _ in range(1, blocks):\n",
    "        layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                            base_width=self.base_width, dilation=self.dilation,\n",
    "                            norm_layer=norm_layer, kernel_size=kernel_size))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "  def _forward_impl(self, x):\n",
    "\n",
    "    xin = x.clone()\n",
    "    x = self.conv1(x)\n",
    "    x = self.bn1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.bn2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.conv3(x)\n",
    "    x = self.bn3(x)\n",
    "    # x = F.max_pool2d(x,2,2)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    # x = self.maxpool(x)\n",
    "    # pdb.set_trace()\n",
    "    x1 = self.layer1(x)\n",
    "    # print(x1.shape)\n",
    "    x2 = self.layer2(x1)\n",
    "    # print(x2.shape)\n",
    "    # x3 = self.layer3(x2)\n",
    "    # # print(x3.shape)\n",
    "    # x4 = self.layer4(x3)\n",
    "    # # print(x4.shape)\n",
    "    # x = F.relu(F.interpolate(self.decoder1(x4), scale_factor=(2,2), mode ='bilinear'))\n",
    "    # x = torch.add(x, x4)\n",
    "    # x = F.relu(F.interpolate(self.decoder2(x4) , scale_factor=(2,2), mode ='bilinear'))\n",
    "    # x = torch.add(x, x3)\n",
    "    # x = F.relu(F.interpolate(self.decoder3(x3) , scale_factor=(2,2), mode ='bilinear'))\n",
    "    # x = torch.add(x, x2)\n",
    "    x = F.relu(F.interpolate(self.decoder4(x2) , scale_factor=(2,2), mode ='bilinear'))\n",
    "    x = torch.add(x, x1)\n",
    "    x = F.relu(F.interpolate(self.decoder5(x) , scale_factor=(2,2), mode ='bilinear'))\n",
    "    # print(x.shape)\n",
    "    \n",
    "    # end of full image training \n",
    "\n",
    "    # y_out = torch.ones((1,2,128,128))\n",
    "    x_loc = x.clone()\n",
    "    # x = F.relu(F.interpolate(self.decoder5(x) , scale_factor=(2,2), mode ='bilinear'))\n",
    "    #start \n",
    "    for i in range(0,4):\n",
    "        for j in range(0,4):\n",
    "\n",
    "            x_p = xin[:,:,32*i:32*(i+1),32*j:32*(j+1)]\n",
    "            # begin patch wise\n",
    "            x_p = self.conv1_p(x_p)\n",
    "            x_p = self.bn1_p(x_p)\n",
    "            # x = F.max_pool2d(x,2,2)\n",
    "            x_p = self.relu(x_p)\n",
    "\n",
    "            x_p = self.conv2_p(x_p)\n",
    "            x_p = self.bn2_p(x_p)\n",
    "            # x = F.max_pool2d(x,2,2)\n",
    "            x_p = self.relu(x_p)\n",
    "            x_p = self.conv3_p(x_p)\n",
    "            x_p = self.bn3_p(x_p)\n",
    "            # x = F.max_pool2d(x,2,2)\n",
    "            x_p = self.relu(x_p)\n",
    "            \n",
    "            # x = self.maxpool(x)\n",
    "            # pdb.set_trace()\n",
    "            x1_p = self.layer1_p(x_p)\n",
    "            # print(x1.shape)\n",
    "            x2_p = self.layer2_p(x1_p)\n",
    "            # print(x2.shape)\n",
    "            x3_p = self.layer3_p(x2_p)\n",
    "            # # print(x3.shape)\n",
    "            x4_p = self.layer4_p(x3_p)\n",
    "            \n",
    "            x_p = F.relu(F.interpolate(self.decoder1_p(x4_p), scale_factor=(2,2), mode ='bilinear'))\n",
    "            x_p = torch.add(x_p, x4_p)\n",
    "            x_p = F.relu(F.interpolate(self.decoder2_p(x_p) , scale_factor=(2,2), mode ='bilinear'))\n",
    "            x_p = torch.add(x_p, x3_p)\n",
    "            x_p = F.relu(F.interpolate(self.decoder3_p(x_p) , scale_factor=(2,2), mode ='bilinear'))\n",
    "            x_p = torch.add(x_p, x2_p)\n",
    "            x_p = F.relu(F.interpolate(self.decoder4_p(x_p) , scale_factor=(2,2), mode ='bilinear'))\n",
    "            x_p = torch.add(x_p, x1_p)\n",
    "            x_p = F.relu(F.interpolate(self.decoder5_p(x_p) , scale_factor=(2,2), mode ='bilinear'))\n",
    "            \n",
    "            x_loc[:,:,32*i:32*(i+1),32*j:32*(j+1)] = x_p\n",
    "\n",
    "    x = torch.add(x,x_loc)\n",
    "    x = F.relu(self.decoderf(x))\n",
    "    \n",
    "    x = self.adjust(F.relu(x))\n",
    "\n",
    "    # pdb.set_trace()\n",
    "    return x\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self._forward_impl(x)\n",
    "\n",
    "def MedT(pretrained=False, **kwargs):\n",
    "    model = medt_net(AxialBlock_dynamic,AxialBlock_wopos, [1, 2, 4, 1], s= 0.125,  **kwargs)\n",
    "    return model\n",
    "\n",
    "def logo(pretrained=False, **kwargs):\n",
    "    model = medt_net(AxialBlock,AxialBlock, [1, 2, 4, 1], s= 0.125, **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85df29a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T17:39:08.162353Z",
     "iopub.status.busy": "2023-12-29T17:39:08.162028Z",
     "iopub.status.idle": "2023-12-29T17:39:08.166403Z",
     "shell.execute_reply": "2023-12-29T17:39:08.165512Z"
    },
    "papermill": {
     "duration": 0.017613,
     "end_time": "2023-12-29T17:39:08.168262",
     "exception": false,
     "start_time": "2023-12-29T17:39:08.150649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn.functional import cross_entropy\n",
    "from torch.nn.modules.loss import _WeightedLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9540affe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T17:39:08.189872Z",
     "iopub.status.busy": "2023-12-29T17:39:08.189584Z",
     "iopub.status.idle": "2023-12-29T17:39:08.204256Z",
     "shell.execute_reply": "2023-12-29T17:39:08.203473Z"
    },
    "papermill": {
     "duration": 0.027738,
     "end_time": "2023-12-29T17:39:08.206100",
     "exception": false,
     "start_time": "2023-12-29T17:39:08.178362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import cross_entropy\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "\n",
    "\n",
    "EPSILON = 1e-32\n",
    "\n",
    "\n",
    "class LogNLLLoss(_WeightedLoss):\n",
    "    __constants__ = ['weight', 'reduction', 'ignore_index']\n",
    "\n",
    "    def __init__(self, weight=None, size_average=None, reduce=None, reduction=None,\n",
    "                 ignore_index=-100):\n",
    "        super(LogNLLLoss, self).__init__(weight, size_average, reduce, reduction)\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def forward(self, y_input, y_target):\n",
    "        # y_input = torch.log(y_input + EPSILON)\n",
    "        return cross_entropy(y_input, y_target, weight=self.weight,\n",
    "                             ignore_index=self.ignore_index)\n",
    "\n",
    "\n",
    "def classwise_iou(output, gt):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        output: torch.Tensor of shape (n_batch, n_classes, image.shape)\n",
    "        gt: torch.LongTensor of shape (n_batch, image.shape)\n",
    "    \"\"\"\n",
    "    #dims = (0, *range(2, len(output.shape)))\n",
    "    #gt = torch.zeros_like(output).scatter_(1, gt[:, None, :], 1)\n",
    "    output = torch.argmax(output, dim=1)\n",
    "    intersection = output*gt\n",
    "    union = output + gt - intersection\n",
    "    #classwise_iou = (intersection.sum(dim=dims).float() + EPSILON) / (union.sum(dim=dims) + EPSILON)\n",
    "    classwise_iou = (intersection.sum().float() + EPSILON) / (union.sum() + EPSILON)\n",
    "    return classwise_iou\n",
    "\n",
    "\n",
    "def classwise_f1(output, gt):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        output: torch.Tensor of shape (n_batch, n_classes, image.shape)\n",
    "        gt: torch.LongTensor of shape (n_batch, image.shape)\n",
    "    \"\"\"\n",
    "\n",
    "    epsilon = 1e-20\n",
    "    n_classes = output.shape[1]\n",
    "\n",
    "    output = torch.argmax(output, dim=1)\n",
    "    #print(output)\n",
    "    true_positives = torch.tensor([((output == i) * (gt == i)).sum() for i in range(n_classes)]).float()\n",
    "    true_positives = true_positives[1].item()\n",
    "    selected = ((output == 1)).sum().float()\n",
    "    relevant = ((gt == 1)).sum().float()\n",
    "    #selected = torch.tensor([(output == i).sum() for i in range(n_classes)]).float()\n",
    "    #relevant = torch.tensor([(gt == i).sum() for i in range(n_classes)]).float()\n",
    "    #print(\"relevant:\",relevant)\n",
    "    #print(\"selected:\",selected)\n",
    "    \n",
    "    precision = (true_positives + epsilon) / (selected + epsilon)\n",
    "    recall = (true_positives + epsilon) / (relevant + epsilon)\n",
    "    #print(precision)\n",
    "    #print(recall)\n",
    "    classwise_f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    return classwise_f1\n",
    "\n",
    "\n",
    "def make_weighted_metric(classwise_metric):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        classwise_metric: classwise metric like classwise_IOU or classwise_F1\n",
    "    \"\"\"\n",
    "\n",
    "    def weighted_metric(output, gt, weights=None):\n",
    "\n",
    "        # dimensions to sum over\n",
    "        dims = (0, *range(2, len(output.shape)))\n",
    "\n",
    "        # default weights\n",
    "        if weights == None:\n",
    "            weights = torch.ones(output.shape[1]) / output.shape[1]\n",
    "        else:\n",
    "            # creating tensor if needed\n",
    "            if len(weights) != output.shape[1]:\n",
    "                raise ValueError(\"The number of weights must match with the number of classes\")\n",
    "            if not isinstance(weights, torch.Tensor):\n",
    "                weights = torch.tensor(weights)\n",
    "            # normalizing weights\n",
    "            weights /= torch.sum(weights)\n",
    "\n",
    "        classwise_scores = classwise_metric(output, gt).cpu()\n",
    "\n",
    "        return classwise_scores \n",
    "\n",
    "    return weighted_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06fa46d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T17:39:08.227824Z",
     "iopub.status.busy": "2023-12-29T17:39:08.227534Z",
     "iopub.status.idle": "2023-12-29T17:39:08.285747Z",
     "shell.execute_reply": "2023-12-29T17:39:08.284746Z"
    },
    "papermill": {
     "duration": 0.071359,
     "end_time": "2023-12-29T17:39:08.287713",
     "exception": false,
     "start_time": "2023-12-29T17:39:08.216354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "lr = 1e-3\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "NUM_EPOCHS = 180\n",
    "IMG_SIZE = 128\n",
    "IMG_CHANEL = 3\n",
    "save_freq = 4\n",
    "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=>Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "def load_checkpoint(checkpoint, model):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c676b4d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T17:39:08.309174Z",
     "iopub.status.busy": "2023-12-29T17:39:08.308813Z",
     "iopub.status.idle": "2023-12-29T17:39:11.134182Z",
     "shell.execute_reply": "2023-12-29T17:39:11.133254Z"
    },
    "papermill": {
     "duration": 2.838602,
     "end_time": "2023-12-29T17:39:11.136546",
     "exception": false,
     "start_time": "2023-12-29T17:39:08.297944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MedT(img_size = IMG_SIZE, imgchan = IMG_CHANEL)\n",
    "model.cuda()\n",
    "criterion = LogNLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6ac4db6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T17:39:11.160318Z",
     "iopub.status.busy": "2023-12-29T17:39:11.159581Z",
     "iopub.status.idle": "2023-12-29T17:39:11.170690Z",
     "shell.execute_reply": "2023-12-29T17:39:11.169817Z"
    },
    "papermill": {
     "duration": 0.025217,
     "end_time": "2023-12-29T17:39:11.172561",
     "exception": false,
     "start_time": "2023-12-29T17:39:11.147344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
    "  train_running_loss = 0\n",
    "  counter = 0\n",
    "  loop = tqdm(loader)\n",
    "  for batch_idx, (data, targets) in enumerate(loop):\n",
    "    data = data.to(device=DEVICE)\n",
    "    targets = targets.long().to(DEVICE)\n",
    "\n",
    "    # forward\n",
    "\n",
    "    with torch.cuda.amp.autocast():\n",
    "      prediction = model(data)\n",
    "      loss = loss_fn(prediction, targets)\n",
    "    \"\"\"\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    scaler.scale(loss).backward()\n",
    "    #loss.backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    #optimizer.step()\n",
    "    \"\"\"\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "    # update tqdm loop\n",
    "    loop.set_postfix(loss = loss.item())\n",
    "    train_running_loss += loss.item()\n",
    "    counter += 1\n",
    "  return train_running_loss / counter\n",
    "\n",
    "def check_accuracy(loader, model, loss_fn, device=\"cuda\"):\n",
    "  my_f1 = 0\n",
    "  my_iou = 0\n",
    "  val_running_loss = 0\n",
    "  with torch.no_grad():\n",
    "    for X, y in loader:\n",
    "      batch_size = X.shape[0]\n",
    "      X = X.to(device)\n",
    "      y = y.long().to(device)\n",
    "      preds = model(X)\n",
    "      loss = loss_fn(preds, y)\n",
    "      val_running_loss += loss.item()\n",
    "      tmp = preds.detach().cpu()\n",
    "      tmp[tmp >= 0.5] = 1\n",
    "      tmp[tmp < 0.5] = 0\n",
    "      tmp2 = y.detach().cpu()\n",
    "      \n",
    "      \n",
    "      tmp = tmp.to(torch.int32)\n",
    "      my_f1 += classwise_f1(tmp, tmp2).item()\n",
    "      my_iou += classwise_iou(tmp, tmp2).item()\n",
    "  print(f\"IoU score: {my_iou/len(loader)}\")\n",
    "  print(f\"F1 score: {my_f1/len(loader)} \")\n",
    "  return val_running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd0d342b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T17:39:11.193695Z",
     "iopub.status.busy": "2023-12-29T17:39:11.193423Z",
     "iopub.status.idle": "2023-12-29T17:39:11.640917Z",
     "shell.execute_reply": "2023-12-29T17:39:11.640034Z"
    },
    "papermill": {
     "duration": 0.460438,
     "end_time": "2023-12-29T17:39:11.643146",
     "exception": false,
     "start_time": "2023-12-29T17:39:11.182708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_checkpoint = torch.load(\"/kaggle/input/checkpoint/my_checkpoint.pth.tar\")\n",
    "model.load_state_dict(my_checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e4d0635",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T17:39:11.665097Z",
     "iopub.status.busy": "2023-12-29T17:39:11.664739Z",
     "iopub.status.idle": "2023-12-29T17:39:11.670326Z",
     "shell.execute_reply": "2023-12-29T17:39:11.669503Z"
    },
    "papermill": {
     "duration": 0.018651,
     "end_time": "2023-12-29T17:39:11.672161",
     "exception": false,
     "start_time": "2023-12-29T17:39:11.653510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b4b05b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T17:39:11.693905Z",
     "iopub.status.busy": "2023-12-29T17:39:11.693630Z",
     "iopub.status.idle": "2023-12-29T22:27:22.713800Z",
     "shell.execute_reply": "2023-12-29T22:27:22.712317Z"
    },
    "papermill": {
     "duration": 17291.034121,
     "end_time": "2023-12-29T22:27:22.716414",
     "exception": false,
     "start_time": "2023-12-29T17:39:11.682293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Epoch 151 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [10:01<00:00,  1.13s/it, loss=0.0829]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Epoch 152 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:57<00:00,  1.12s/it, loss=0.0523]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>Saving checkpoint\n",
      "IoU score: 0.8124062285494449\n",
      "F1 score: 0.8963643872915809 \n",
      "============Epoch 153 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:57<00:00,  1.12s/it, loss=0.0569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Epoch 154 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:55<00:00,  1.12s/it, loss=0.0492]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Epoch 155 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:54<00:00,  1.11s/it, loss=0.0443]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Epoch 156 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:53<00:00,  1.11s/it, loss=0.042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>Saving checkpoint\n",
      "IoU score: 0.8811565121607994\n",
      "F1 score: 0.9367629698852995 \n",
      "============Epoch 157 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:52<00:00,  1.11s/it, loss=0.0462]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Epoch 158 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:52<00:00,  1.11s/it, loss=0.0413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Epoch 159 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:51<00:00,  1.11s/it, loss=0.0534]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Epoch 160 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:52<00:00,  1.11s/it, loss=0.0445]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>Saving checkpoint\n",
      "IoU score: 0.9033456346881923\n",
      "F1 score: 0.9491792321205139 \n",
      "============Epoch 161 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:48<00:00,  1.10s/it, loss=0.037]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Epoch 162 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:44<00:00,  1.10s/it, loss=0.0451]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Epoch 163 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:44<00:00,  1.10s/it, loss=0.0375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Epoch 164 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:44<00:00,  1.10s/it, loss=0.0398]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>Saving checkpoint\n",
      "IoU score: 0.8927426071309331\n",
      "F1 score: 0.9432954948339889 \n",
      "============Epoch 165 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:44<00:00,  1.10s/it, loss=0.0327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Epoch 166 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:43<00:00,  1.10s/it, loss=0.0371]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Epoch 167 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:44<00:00,  1.10s/it, loss=0.0335]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Epoch 168 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:43<00:00,  1.09s/it, loss=0.0347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>Saving checkpoint\n",
      "IoU score: 0.9064489718693406\n",
      "F1 score: 0.9508954766970962 \n",
      "============Epoch 169 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:43<00:00,  1.09s/it, loss=0.0453]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Epoch 170 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:42<00:00,  1.09s/it, loss=0.0389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Epoch 171 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:43<00:00,  1.09s/it, loss=0.0355]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Epoch 172 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:43<00:00,  1.09s/it, loss=0.0315]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>Saving checkpoint\n",
      "IoU score: 0.9173822563085983\n",
      "F1 score: 0.956880287447972 \n",
      "============Epoch 173 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:42<00:00,  1.09s/it, loss=0.0292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Epoch 174 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:43<00:00,  1.09s/it, loss=0.0329]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Epoch 175 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:43<00:00,  1.09s/it, loss=0.0382]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Epoch 176 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:43<00:00,  1.09s/it, loss=0.0437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>Saving checkpoint\n",
      "IoU score: 0.9209727057770117\n",
      "F1 score: 0.9588371239491363 \n",
      "============Epoch 177 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:42<00:00,  1.09s/it, loss=0.0393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Epoch 178 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:42<00:00,  1.09s/it, loss=0.0374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Epoch 179 ============ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [09:42<00:00,  1.09s/it, loss=0.0327]\n"
     ]
    }
   ],
   "source": [
    "loss_history = {\"train\":[], \"val\":[]}\n",
    "for epoch in range(151, NUM_EPOCHS):\n",
    "  #model.cuda()\n",
    "  print(f\"============Epoch {epoch} ============ \")\n",
    "  train_loss = train_fn(train_loader, model, optimizer, criterion, scaler)\n",
    "  \"\"\"\n",
    "  if epoch == 10:\n",
    "    for param in model.parameters():\n",
    "      param.requires_grad = True\n",
    "  \"\"\"\n",
    "  if (epoch % save_freq) == 0:\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\" : optimizer.state_dict(),\n",
    "    }\n",
    "    save_checkpoint(checkpoint)\n",
    "    val_loss = check_accuracy(val_loader, model, criterion, DEVICE)\n",
    "    loss_history[\"val\"].append(val_loss)\n",
    "    loss_history[\"train\"].append(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c59e5fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T22:27:27.767716Z",
     "iopub.status.busy": "2023-12-29T22:27:27.767329Z",
     "iopub.status.idle": "2023-12-29T22:28:03.377104Z",
     "shell.execute_reply": "2023-12-29T22:28:03.375766Z"
    },
    "papermill": {
     "duration": 40.579058,
     "end_time": "2023-12-29T22:28:05.811039",
     "exception": false,
     "start_time": "2023-12-29T22:27:25.231981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU score: 0.9185649236636375\n",
      "F1 score: 0.9575326736293622 \n"
     ]
    }
   ],
   "source": [
    "test_loss = check_accuracy(test_loader, model, criterion, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc90fac0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T22:28:10.929690Z",
     "iopub.status.busy": "2023-12-29T22:28:10.928791Z",
     "iopub.status.idle": "2023-12-29T22:28:11.673144Z",
     "shell.execute_reply": "2023-12-29T22:28:11.672188Z"
    },
    "papermill": {
     "duration": 3.301194,
     "end_time": "2023-12-29T22:28:11.675282",
     "exception": false,
     "start_time": "2023-12-29T22:28:08.374088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_index = torch.randint(0, len(test_ds),size=(1,)).item()\n",
    "with torch.no_grad():\n",
    "    X_test, y_test = test_ds[my_index]\n",
    "    pred_test = model(X_test.unsqueeze(0).cuda())\n",
    "    pred_test = torch.argmax(pred_test, dim=1)\n",
    "    my_figrue, axarr = plt.subplots(1,3)\n",
    "    axarr[0].imshow(X_test.cpu().transpose(0,2).transpose(0,1))\n",
    "    axarr[1].imshow(y_test.cpu())\n",
    "    axarr[2].imshow(pred_test.squeeze(0).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c1fc6c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T22:28:16.623781Z",
     "iopub.status.busy": "2023-12-29T22:28:16.623426Z",
     "iopub.status.idle": "2023-12-29T22:28:16.774739Z",
     "shell.execute_reply": "2023-12-29T22:28:16.773767Z"
    },
    "papermill": {
     "duration": 2.68616,
     "end_time": "2023-12-29T22:28:16.777177",
     "exception": false,
     "start_time": "2023-12-29T22:28:14.091017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>Saving checkpoint\n",
      "saved\n"
     ]
    }
   ],
   "source": [
    "save_checkpoint(checkpoint)\n",
    "print('saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e2ead0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T12:48:53.833108Z",
     "iopub.status.busy": "2023-12-28T12:48:53.832230Z",
     "iopub.status.idle": "2023-12-28T12:48:55.393270Z",
     "shell.execute_reply": "2023-12-28T12:48:55.392008Z",
     "shell.execute_reply.started": "2023-12-28T12:48:53.833074Z"
    },
    "papermill": {
     "duration": 2.484467,
     "end_time": "2023-12-29T22:28:21.813178",
     "exception": false,
     "start_time": "2023-12-29T22:28:19.328711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b608859a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T12:37:09.637504Z",
     "iopub.status.busy": "2023-12-28T12:37:09.636741Z",
     "iopub.status.idle": "2023-12-28T12:37:12.082134Z",
     "shell.execute_reply": "2023-12-28T12:37:12.081255Z",
     "shell.execute_reply.started": "2023-12-28T12:37:09.637466Z"
    },
    "papermill": {
     "duration": 2.538009,
     "end_time": "2023-12-29T22:28:26.890692",
     "exception": false,
     "start_time": "2023-12-29T22:28:24.352683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da69b8b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T16:19:46.995795Z",
     "iopub.status.busy": "2023-12-28T16:19:46.995415Z",
     "iopub.status.idle": "2023-12-28T16:20:03.093003Z",
     "shell.execute_reply": "2023-12-28T16:20:03.091266Z",
     "shell.execute_reply.started": "2023-12-28T16:19:46.995765Z"
    },
    "papermill": {
     "duration": 2.531454,
     "end_time": "2023-12-29T22:28:31.831489",
     "exception": false,
     "start_time": "2023-12-29T22:28:29.300035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cb0b7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T16:24:53.129715Z",
     "iopub.status.busy": "2023-12-28T16:24:53.129312Z",
     "iopub.status.idle": "2023-12-28T16:24:53.267748Z",
     "shell.execute_reply": "2023-12-28T16:24:53.266447Z",
     "shell.execute_reply.started": "2023-12-28T16:24:53.129682Z"
    },
    "papermill": {
     "duration": 2.413562,
     "end_time": "2023-12-29T22:28:36.847234",
     "exception": false,
     "start_time": "2023-12-29T22:28:34.433672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff49255",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T16:18:37.596784Z",
     "iopub.status.busy": "2023-12-28T16:18:37.595843Z",
     "iopub.status.idle": "2023-12-28T16:18:37.949112Z",
     "shell.execute_reply": "2023-12-28T16:18:37.947917Z",
     "shell.execute_reply.started": "2023-12-28T16:18:37.596738Z"
    },
    "papermill": {
     "duration": 2.567568,
     "end_time": "2023-12-29T22:28:41.969187",
     "exception": false,
     "start_time": "2023-12-29T22:28:39.401619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d86d8f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T13:36:31.205434Z",
     "iopub.status.busy": "2023-12-28T13:36:31.204540Z",
     "iopub.status.idle": "2023-12-28T13:36:31.831453Z",
     "shell.execute_reply": "2023-12-28T13:36:31.830234Z",
     "shell.execute_reply.started": "2023-12-28T13:36:31.205395Z"
    },
    "papermill": {
     "duration": 2.51528,
     "end_time": "2023-12-29T22:28:46.883141",
     "exception": false,
     "start_time": "2023-12-29T22:28:44.367861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b08e364",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T16:53:09.558937Z",
     "iopub.status.busy": "2023-12-28T16:53:09.558576Z",
     "iopub.status.idle": "2023-12-28T16:53:11.438374Z",
     "shell.execute_reply": "2023-12-28T16:53:11.437426Z",
     "shell.execute_reply.started": "2023-12-28T16:53:09.558907Z"
    },
    "papermill": {
     "duration": 2.42722,
     "end_time": "2023-12-29T22:28:51.827132",
     "exception": false,
     "start_time": "2023-12-29T22:28:49.399912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5839,
     "sourceId": 18613,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4177129,
     "sourceId": 7217573,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4232590,
     "sourceId": 7296870,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17766.124601,
   "end_time": "2023-12-29T22:28:56.846408",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-29T17:32:50.721807",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
